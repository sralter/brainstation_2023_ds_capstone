{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afe2082",
   "metadata": {},
   "source": [
    "# Welcome  \n",
    "\n",
    "Notebook Author: Samuel Alter  \n",
    "Notebook Subject: Capstone Project - Preprocess Imagery\n",
    "\n",
    "BrainStation Winter 2023: Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22225f7-5492-4286-adb0-8fa32a548cf9",
   "metadata": {},
   "source": [
    "This notebook is for processing the satellite into tiles or 'patches' for modelling, and cleaning the files to ensure only square images are fed into the image analysis.\n",
    "\n",
    "The satellite images processed here were already patched in QGIS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf2e13-67ce-4af6-b325-a63e2ec0565e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "617c7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e2698-6c4c-4c4b-8b7b-d88dd2658abe",
   "metadata": {},
   "source": [
    "# Preprocess Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52945d-cff0-4954-9f40-6a08bc04c000",
   "metadata": {},
   "source": [
    "### First, create a function for flow control. If a file was already created in a folder, then when put in an if statement, this function can prevent such actions from occurring. Its also just a handy function to check how many files are in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9cc0d172-293f-44b9-b799-4f4865a23db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filePresenceSumChecker(directory:str,extension:str,count=True,verbose=False):\n",
    "    '''\n",
    "    Checks the sum of all the files with a certain extension.\n",
    "    \n",
    "    Useful to see if a file move process has already been completed.\n",
    "    \n",
    "    ----\n",
    "    Inputs\n",
    "    \n",
    "    >directory\n",
    "    path to a folder to check if files are there\n",
    "    \n",
    "    >extension\n",
    "    user-specified extension to only count those files\n",
    "    \n",
    "    >verbose\n",
    "    option for the user to see how many files with the extension \n",
    "    is in the directory provided\n",
    "    \n",
    "    >count\n",
    "    option for the user to see the count of the files\n",
    "    \n",
    "    ----\n",
    "    Outputs\n",
    "    \n",
    "    >counter\n",
    "    gives the amount of files within the directory\n",
    "    '''\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    # get a list of all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # iterate through the files and check if any have the specified extension\n",
    "    for file in files:\n",
    "        if file.endswith(extension):\n",
    "            counter+=1\n",
    "                \n",
    "    if verbose==True:\n",
    "        print(f\"There are {counter} '{extension}' files within {directory}.\")\n",
    "\n",
    "    if count==True:\n",
    "        return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a57ff7-e015-4e9a-aee6-6d5c325dcc15",
   "metadata": {
    "tags": []
   },
   "source": [
    "Determine how many individual patch images are in the full patch dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7245f78-e7fe-443e-8b22-f41d12bd8482",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same size\n",
      "the size of city_ct is 7761\n",
      "the size of farm_ct is 2496\n",
      "the size of fire1_ct is 7761\n",
      "the size of fire2_ct is 2496\n"
     ]
    }
   ],
   "source": [
    "# setup paths\n",
    "# farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_farm'\n",
    "# city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_city'\n",
    "# fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire1'\n",
    "# fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire2'\n",
    "\n",
    "farm='./patches/patch_nofire_farm'\n",
    "city='./patches/patch_nofire_city'\n",
    "fire1='./patches/patch_fire_fire1'\n",
    "fire2='./patches/patch_fire_fire2'\n",
    "\n",
    "# save counts\n",
    "farm_ct=filePresenceSumChecker(directory=farm,extension='.tif')\n",
    "city_ct=filePresenceSumChecker(directory=city,extension='.tif')\n",
    "fire1_ct=filePresenceSumChecker(directory=fire1,extension='.tif')\n",
    "fire2_ct=filePresenceSumChecker(directory=fire2,extension='.tif')\n",
    "\n",
    "# sum fire patch counts together and nofire patch counts together\n",
    "sum_nofire=farm_ct+city_ct\n",
    "sum_fire=fire1_ct+fire2_ct\n",
    "\n",
    "# check if the sums are the same\n",
    "if sum_nofire==sum_nofire:\n",
    "    print('same size')\n",
    "    print(f'the size of city_ct is {city_ct}')\n",
    "    print(f'the size of farm_ct is {farm_ct}')\n",
    "    print(f'the size of fire1_ct is {fire1_ct}')\n",
    "    print(f'the size of fire2_ct is {fire2_ct}')\n",
    "else:\n",
    "    print('not the same size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340aea25-dfa3-4afe-b023-4642855c2729",
   "metadata": {},
   "source": [
    "The size of the image patches are the same per category, effectively building a labeled dataset with $50\\%$ images being from fire areas and $50\\%$ from nofire areas. \n",
    "\n",
    "**However**, and this is very important, some of the images are not square, which means that the point layer did not capture the area of these images. Therefore, the nonsquare images will be removed later in the notebook. Accordingly, the number of images will decrease when the nonsquare patches will be moved away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3363457-b4d1-4786-be47-14905ab04e04",
   "metadata": {},
   "source": [
    "The images are in four folders. Though all images have names corresponding to their folder, they have similar numbers across the folders. For example, the folder `patch_nofire_farm` has images with the pattern `patch_nofire_farm.XXXX.tif`. Images from the `patch_nofire_city` folder have the pattern `patch_nofire_city.XXXX.tif`, and the numbers from the `_farm` folder are repeated in the `_city` folder. I want the numbers to be different so that, as the file counting function above demonstrates:\n",
    "* The images from `city` are numbered `0` through `7761`\n",
    "* The images from `farm` are numbered `7762` through `10257`\n",
    "* And so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a102303-7744-475d-bf06-97926a84f574",
   "metadata": {},
   "source": [
    "### Rename the files to remove the period between the `_farm`/`_city`/etc. and `XXXX`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ba731d-9c41-4f44-86f8-f9533016e202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fileRenamer(source:str, prefix:str,extension='.tif',verbose=False):\n",
    "    '''\n",
    "    Renames files to the format provided by the user.\n",
    "    It can help clean an image format to one that can be\n",
    "    read by modules like Tensorflow.\n",
    "    \n",
    "    Note: code will break if there are no files with a number\n",
    "    suffix separated by a period. Put the function in a flow\n",
    "    control loop first.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >source\n",
    "    the directory where the files are located\n",
    "    \n",
    "    >prefix\n",
    "    the base part of the filename that will remain\n",
    "    \n",
    "    >extension\n",
    "    defaults to '.tif', but this will ensure you only rename\n",
    "    certain files that have the specified extension\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    renames files in-place, no further output\n",
    "    \n",
    "    ----\n",
    "    Example:\n",
    "    >>source='/patch_nofire_farm.0.tif'\n",
    "    >>fileRenamer(source=source,prefix='patch_nofire_farm',extension='.tif')\n",
    "    >>patch_nofire_farm_testing_0.tif\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # loop over each file from the source directory\n",
    "    for filename in os.listdir(source):\n",
    "        if verbose==True:\n",
    "            print('filename:',filename)\n",
    "        \n",
    "        # check if the file is the provided `ext` (extension)\n",
    "        if filename.endswith(extension):\n",
    "            \n",
    "            # split the filename into base and extension\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            if verbose==True:\n",
    "                print('base:',base)\n",
    "                print('ext:',ext)\n",
    "            \n",
    "            # split the base into the prefix and number parts\n",
    "            prefix, number = base.split('.', 1)\n",
    "            if verbose==True:\n",
    "                print('prefix:',prefix)\n",
    "                print('number:',number)\n",
    "            \n",
    "            # create the new filename with the desired format\n",
    "            new_filename = f'{prefix}_{number}{ext}'\n",
    "            if verbose==True:\n",
    "                print('new_filename:',new_filename)\n",
    "            \n",
    "            # rename the file\n",
    "            os.rename(os.path.join(source, filename), \n",
    "                      os.path.join(source, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "616ceba9-18f9-462c-b9c3-1e2c399f706e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing renaming function\n",
    "# directory='/Users/sra/temp/'\n",
    "# prefix_='patch_nofire_city'\n",
    "\n",
    "# fileRenamer(source=directory,prefix=prefix_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13401471-6792-45bf-b899-09168efc5101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write function to check if files have already been renamed\n",
    "# this is for flow control\n",
    "\n",
    "def checkFileString(directory_path, file_string):\n",
    "    '''\n",
    "    Takes a directory and string and checks if the string is\n",
    "    included in any of the filenames within the directory.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >directory_path\n",
    "    User-specified path to look for the filenames\n",
    "    \n",
    "    >file_string\n",
    "    User-specified string that the function will look for\n",
    "    '''\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if file_string in filename:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee92ef7c-ae32-4225-ad85-fa02b5e96586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup lists\n",
    "# to run renaming function\n",
    "\n",
    "# city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_city'\n",
    "# farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_farm'\n",
    "# fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire1'\n",
    "# fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire2'\n",
    "\n",
    "city='./patches/patch_nofire_city'\n",
    "farm='./patches/patch_nofire_farm'\n",
    "fire1='./patches/patch_fire_fire1'\n",
    "fire2='./patches/patch_fire_fire2'\n",
    "\n",
    "\n",
    "sources=[city,farm,#nofire\n",
    "        fire1,fire2]#fire\n",
    "\n",
    "prefix_city='patch_nofire_city'\n",
    "prefix_farm='patch_nofire_farm'\n",
    "prefix_fire1='patch_nofire_fire1'\n",
    "prefix_fire2='patch_nofire_fire2'\n",
    "\n",
    "prefixes=[prefix_city,prefix_farm,\n",
    "         prefix_fire1,prefix_fire2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb7a2506-dbc2-4c7d-8a3d-bc1039a38693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run fileRenamer on all the patches:\n",
    "# city #nofire\n",
    "# farm #nofire\n",
    "# fire1 #fire\n",
    "# fire2 #fire\n",
    "\n",
    "# setup directory for flow control file string checker function\n",
    "# directory='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_city'\n",
    "directory='./patches/patch_nofire_city'\n",
    "\n",
    "if checkFileString(directory_path=directory,file_string='patch_nofire_city_') == False:\n",
    "    for src,pref in zip(sources,prefixes):\n",
    "        fileRenamer(source=src,prefix=pref,extension='.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ae14d-43af-4a60-a84c-f0134a913ce1",
   "metadata": {},
   "source": [
    "Checking the filenames shows that they have been changed to swap the `.` for a `_`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706d513-7d15-4ba5-a602-295e8973cc36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b434efe-0378-4d60-a44e-ed12de16f60e",
   "metadata": {},
   "source": [
    "Now I need to remove the non-square images from the folders because the point-creation tool (see geoanalysis and report) did not make points for the images that are on the margin of the four areas (`city`, `farm`, `fire1`, `fire2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca8921-b41a-4bf6-9396-eaf69586c49f",
   "metadata": {},
   "source": [
    "This needs to happen before I rename the images because the numbers corresponding to the images need to correspond to the geographic dataset. In other words, the ideal situation would be that point `18` in the geographic dataset corresponds to the exact location of image `18`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43720973-6003-4e3d-aec5-b73daac59d2c",
   "metadata": {},
   "source": [
    "First, though, the photos need to be converted from `.tif` to `.jpg`. This will be achieved through a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df81bd9-864e-4ca8-add5-2d59635640d6",
   "metadata": {},
   "source": [
    "### Convert `.tif` to `.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43442ea0-9f8a-430e-9968-cb859bf3f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageConverter(inputPath, outputPath, oldExtension='.tif',newExtension='.jpg',fileType='JPEG',verbose=False):\n",
    "    '''\n",
    "    Iterates through a directory of (default) .tif files and \n",
    "    converts them to (default) .jpg format using the Pillow library.\n",
    "    \n",
    "    The images will be sent to a new folder.\n",
    "\n",
    "    Requires an input directory path \n",
    "    and an output directory path as strings.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >inputPath\n",
    "    string path to where the inputs are located\n",
    "    \n",
    "    >outputPath\n",
    "    string path to where the outputs will be located\n",
    "    '''\n",
    "\n",
    "    # create the output directory if it doesn't exist\n",
    "    # os.makedirs(outputPath, exist_ok=True)\n",
    "\n",
    "    # iterate through all files in the input directory\n",
    "    for file_name in os.listdir(inputPath):\n",
    "        if file_name.endswith(oldExtension):\n",
    "            # construct the input and output file paths\n",
    "            input_path = os.path.join(inputPath, file_name)\n",
    "            output_path = os.path.join(outputPath, \n",
    "                                       file_name.replace(oldExtension,\n",
    "                                                         newExtension))\n",
    "\n",
    "            # load the image\n",
    "            # https://stackoverflow.com/questions/40751523/how-do-you-read-a-32-bit-tiff-image-in-python\n",
    "            img = cv2.imread(input_path,-1)\n",
    "            \n",
    "            # convert to RGB format if necessary\n",
    "            if img.shape[2] == 1:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            elif img.shape[2] == 4:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "\n",
    "            # Save the image as a .jpg file\n",
    "            cv2.imwrite(output_path, img, [int(cv2.IMWRITE_JPEG_QUALITY), 90])\n",
    "            \n",
    "            if verbose==True:\n",
    "                print(f\"Conversion complete: {input_path} -> {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeda35df-a209-4e92-b02b-9e49b40d02d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # test function\n",
    "\n",
    "# inp='/Users/sra/temp/'\n",
    "# out='/Users/sra/temp2'\n",
    "\n",
    "# imageConverter(inputPath=inp,outputPath=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9db9f5fe-3388-444b-bbd5-f642793fd4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup lists for jpg converter function\n",
    "\n",
    "# source_city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_city'\n",
    "# source_farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_farm'\n",
    "# source_fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire1'\n",
    "# source_fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire2'\n",
    "\n",
    "source_city='./patches/patch_nofire_city'\n",
    "source_farm='./patches/patch_nofire_farm'\n",
    "source_fire1='./patches/patch_fire_fire1'\n",
    "source_fire2='./patches/patch_fire_fire2'\n",
    "\n",
    "\n",
    "sources=[source_city,\n",
    "        source_farm,\n",
    "        source_fire1,\n",
    "        source_fire2]\n",
    "\n",
    "# dest_city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/city'\n",
    "# dest_farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/farm'\n",
    "# dest_fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire1'\n",
    "# dest_fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2'\n",
    "\n",
    "dest_city='./patches/_patch_jpg/city'\n",
    "dest_farm='./patches/_patch_jpg/farm'\n",
    "dest_fire1='./patches/_patch_jpg/fire1'\n",
    "dest_fire2='./patches/_patch_jpg/fire2'\n",
    "\n",
    "\n",
    "dests=[dest_city,\n",
    "      dest_farm,\n",
    "      dest_fire1,\n",
    "      dest_fire2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "96256678-41a4-4fe7-95b7-3ec5cf75f3e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# source='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2'\n",
    "source='./patches/_patch_jpg/fire2'\n",
    "\n",
    "if filePresenceSumChecker(directory=source,extension='.jpg')==0:\n",
    "    for src,des in zip(sources,dests):\n",
    "        imageConverter(inputPath=src,outputPath=des)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a527f-8944-47d8-bd09-5af588de9e06",
   "metadata": {},
   "source": [
    "Now we can move the nonsquare `.jpg` images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c41f04eb-73df-431b-aec2-616b3028ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveNonSquareJPG(source_folder:str, destination_folder:str):\n",
    "    '''\n",
    "    Checks to see if any JPG or PNG in the source folder\n",
    "    does not have square dimensions (e.g. 29x128 is not square,\n",
    "    128x128 is).\n",
    "    \n",
    "    If they do, they are sent to the destination_folder.\n",
    "    \n",
    "    ----\n",
    "    Inputs\n",
    "    \n",
    "    >source_folder\n",
    "    the source of the images to be checked\n",
    "    \n",
    "    >destination_folder\n",
    "    where the non-square images will be relocated to\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Create destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    \n",
    "    # get a list of all image files in the source folder\n",
    "    image_files = [f for f in os.listdir(source_folder) if \\\n",
    "                   f.endswith('.jpg') or \\\n",
    "                   f.endswith('.jpeg') or \\\n",
    "                   f.endswith('.png')]\n",
    "    \n",
    "    for file_name in image_files:\n",
    "        # open the image using PIL\n",
    "        img = Image.open(os.path.join(source_folder, file_name))\n",
    "        \n",
    "        # check if image is square\n",
    "        if img.size[0] != img.size[1]:\n",
    "            # move the image to the destination folder\n",
    "            shutil.move(os.path.join(source_folder, file_name), os.path.join(destination_folder, file_name))\n",
    "            # # delete the non-square image from the source folder\n",
    "            # os.remove(os.path.join(source_folder, file_name))\n",
    "        \n",
    "    # friendly notice\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa4082b9-1389-4618-9992-90ade8ad2192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # test function\n",
    "# source_='/Users/sra/temp2'\n",
    "# dest_='/Users/sra/temp'\n",
    "\n",
    "# moveNonSquareJPG(source_folder=source_,destination_folder=dest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b462e2ee-d441-4210-9f3d-28a841f6d07e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup lists for function\n",
    "\n",
    "# source_city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/city'\n",
    "# source_farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/farm'\n",
    "# source_fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire1'\n",
    "# source_fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2'\n",
    "\n",
    "source_city='./patches/_patch_jpg/city'\n",
    "source_farm='./patches/_patch_jpg/farm'\n",
    "source_fire1='./patches/_patch_jpg/fire1'\n",
    "source_fire2='./patches/_patch_jpg/fire2'\n",
    "\n",
    "\n",
    "sources=[source_city,\n",
    "        source_farm,\n",
    "        source_fire1,\n",
    "        source_fire2]\n",
    "\n",
    "# dest_city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/jpg/city'\n",
    "# dest_farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/jpg/farm'\n",
    "# dest_fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/jpg/fire1'\n",
    "# dest_fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/jpg/fire2'\n",
    "\n",
    "dest_city='./patches/nonsquares/jpg/city'\n",
    "dest_farm='./patches/nonsquares/jpg/farm'\n",
    "dest_fire1='./patches/nonsquares/jpg/fire1'\n",
    "dest_fire2='./patches/nonsquares/jpg/fire2'\n",
    "\n",
    "\n",
    "dests=[dest_city,\n",
    "      dest_farm,\n",
    "      dest_fire1,\n",
    "      dest_fire2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7aca16e3-2a27-4d21-a24e-3fa43f16d5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# setup flow control\n",
    "\n",
    "# directory_='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/jpg/city'\n",
    "directory_='./patches/nonsquares/jpg/city'\n",
    "\n",
    "if filePresenceSumChecker(directory=directory_,extension='.jpg') == 0:\n",
    "    for src,dest in zip(sources,dests):\n",
    "        moveNonSquareJPG(source_folder=src,\n",
    "                         destination_folder=dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649eeca3-9cce-4dc6-957a-e8d1db45cdc4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641c6c2-4d2a-4827-8d57-8feebc4f2880",
   "metadata": {},
   "source": [
    "### `train`/`valid`/`test` Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89836d46-6202-42bb-870b-cf61d5fe29b9",
   "metadata": {},
   "source": [
    "#### Get the number of images in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "023cd572-1353-463a-8180-d0e7062a2d38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same size\n",
      "the size of city_ct is 0\n",
      "the size of farm_ct is 0\n",
      "the size of fire1_ct is 0\n",
      "the size of fire2_ct is 0\n"
     ]
    }
   ],
   "source": [
    "# setup paths\n",
    "# city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/city'\n",
    "# farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/farm'\n",
    "# fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire1'\n",
    "# fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2'\n",
    "\n",
    "city='./patches/_patch_jpg/city'\n",
    "farm='./_patch_jpg/farm'\n",
    "fire1='./_patch_jpg/fire1'\n",
    "fire2='./patches/_patch_jpg/fire2'\n",
    "\n",
    "\n",
    "# save counts\n",
    "farm_ct=filePresenceSumChecker(directory=farm,extension='.jpg')\n",
    "city_ct=filePresenceSumChecker(directory=city,extension='.jpg')\n",
    "fire1_ct=filePresenceSumChecker(directory=fire1,extension='.jpg')\n",
    "fire2_ct=filePresenceSumChecker(directory=fire2,extension='.jpg')\n",
    "\n",
    "# sum fire patch counts together and nofire patch counts together\n",
    "sum_nofire=farm_ct+city_ct\n",
    "sum_fire=fire1_ct+fire2_ct\n",
    "\n",
    "# check if the sums are the same\n",
    "if sum_nofire==sum_nofire:\n",
    "    print('same size')\n",
    "    print(f'the size of city_ct is {city_ct}')\n",
    "    print(f'the size of farm_ct is {farm_ct}')\n",
    "    print(f'the size of fire1_ct is {fire1_ct}')\n",
    "    print(f'the size of fire2_ct is {fire2_ct}')\n",
    "else:\n",
    "    print('not the same size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8815920e-3c1b-40f3-892e-90ac88e16b24",
   "metadata": {},
   "source": [
    "**Reminder: the number of images corresponds exactly to the number of points in the geographic dataset. This is a very, very important check to ensure that the eventual metamodel can be created properly**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0ae3d6-d8ae-42b1-bed5-ac2f6961ddc8",
   "metadata": {},
   "source": [
    "#### Reset the number suffix on each image to prepare for `train`/`valid`/`test` splits\n",
    "\n",
    "The numbers on the geographic dataset will also be reset. Each patch, (city, farm, fire1, fire2) will be reset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ebe39a0-b989-4a9f-b198-2211e6f5a369",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resetFileNumbers(directory: str, prefix: str):\n",
    "    '''\n",
    "    Resets the numbering in filenames \n",
    "    in the provided directory.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >directory\n",
    "    the directory where the files are located\n",
    "    \n",
    "    >prefix\n",
    "    the prefix part of the filename that will remain\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    renames files in-place, no further output\n",
    "    \n",
    "    ----\n",
    "    Example:\n",
    "    >>directory='./files'\n",
    "    >>prefix='file_'\n",
    "    >>reset_file_numbers(directory=directory,prefix=prefix)\n",
    "    >>file_0\n",
    "    >>file_1\n",
    "    >>file_2\n",
    "    '''\n",
    "\n",
    "    # create a list of all the files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # filter only the files with the prefix provided\n",
    "    files = [f for f in files if f.startswith(prefix)]\n",
    "\n",
    "    # sort the files by their numerical suffix\n",
    "    files.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "\n",
    "    # rename the files with the new numbering\n",
    "    for i, filename in enumerate(files):\n",
    "        new_filename = prefix + str(i) + os.path.splitext(filename)[1]\n",
    "        os.rename(os.path.join(directory, filename),\n",
    "                  os.path.join(directory, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "586eebcc-1633-4283-8e5f-7f6aed02c288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test function\n",
    "\n",
    "# directory_='/Users/sra/temp'\n",
    "\n",
    "# resetFileNumbers(directory=directory_,prefix='patch_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e128bac-0532-4cb9-b654-3c3b404e5b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# city=7525\n",
    "# farm=2395\n",
    "# fire1=7525\n",
    "# fire2=2395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0821eb6b-a316-4909-b936-496ffb549c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup lists\n",
    "\n",
    "# dir_city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/city'\n",
    "# dir_farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/farm'\n",
    "# dir_fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire1'\n",
    "# dir_fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2'\n",
    "\n",
    "dir_city='./patches/_patch_jpg/city'\n",
    "dir_farm='./patches/_patch_jpg/farm'\n",
    "dir_fire1='./patches/_patch_jpg/fire1'\n",
    "dir_fire2='./patches/_patch_jpg/fire2'\n",
    "\n",
    "\n",
    "dirs=[dir_city,dir_farm,dir_fire1,dir_fire2]\n",
    "\n",
    "prefix_city='patch_nofire_city_'\n",
    "prefix_farm='patch_nofire_farm_'\n",
    "prefix_fire1='patch_fire_fire1_'\n",
    "prefix_fire2='patch_fire_fire2_'\n",
    "\n",
    "prefixes=[prefix_city,prefix_farm,prefix_fire1,prefix_fire2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4c4a8e1b-f19d-43bc-8f8a-f6486686e14b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# flow control and rename images\n",
    "\n",
    "# destination_folder='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/city/flow_control'\n",
    "# destination='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/city'\n",
    "\n",
    "destination_folder='./patches/_patch_jpg/city/flow_control'\n",
    "destination='./patches/_patch_jpg/city'\n",
    "\n",
    "\n",
    "if not os.path.exists(destination_folder):\n",
    "    for dr,prf in zip(dirs,prefixes):\n",
    "        resetFileNumbers(directory=dr,prefix=prf)\n",
    "        \n",
    "    # create the full path to the new folder\n",
    "    new_folder_path = os.path.join(destination, 'flow_control')\n",
    "\n",
    "    # create the new folder if it doesn't already exist\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8115af3-ae1d-4857-8360-e3be394e71c1",
   "metadata": {},
   "source": [
    "Now to the train/test split. To do this, we will create function to generate lists of unique numbers that will serve as the random selector for setting up train/test/validation splits:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac339be-5505-439b-9353-668d77fd1a59",
   "metadata": {},
   "source": [
    "First, count the number of files in each folder as before to confirm the total_img size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b6dc664-c867-41d2-b6aa-2197e5836bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'city' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m dir_fire2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# save counts\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m city_ct\u001b[38;5;241m=\u001b[39mfilePresenceSumChecker(directory\u001b[38;5;241m=\u001b[39m\u001b[43mcity\u001b[49m,extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m farm_ct\u001b[38;5;241m=\u001b[39mfilePresenceSumChecker(directory\u001b[38;5;241m=\u001b[39mfarm,extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m fire1_ct\u001b[38;5;241m=\u001b[39mfilePresenceSumChecker(directory\u001b[38;5;241m=\u001b[39mfire1,extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'city' is not defined"
     ]
    }
   ],
   "source": [
    "# setup paths\n",
    "# dir_city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/city'\n",
    "# dir_farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/farm'\n",
    "# dir_fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire1'\n",
    "# dir_fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2'\n",
    "\n",
    "dir_city='./patches/_patch_jpg/city'\n",
    "dir_farm='./patches/_patch_jpg/farm'\n",
    "dir_fire1='./patches/_patch_jpg/fire1'\n",
    "dir_fire2='./patches/_patch_jpg/fire2'\n",
    "\n",
    "\n",
    "# save counts\n",
    "city_ct=filePresenceSumChecker(directory=city,extension='.jpg')\n",
    "farm_ct=filePresenceSumChecker(directory=farm,extension='.jpg')\n",
    "fire1_ct=filePresenceSumChecker(directory=fire1,extension='.jpg')\n",
    "fire2_ct=filePresenceSumChecker(directory=fire2,extension='.jpg')\n",
    "\n",
    "# sum fire patch counts together and nofire patch counts together\n",
    "sum_nofire=city_ct+farm_ct\n",
    "sum_fire=fire1_ct+fire2_ct\n",
    "\n",
    "# check if the sums are the same\n",
    "if sum_nofire==sum_nofire:\n",
    "    print('same size')\n",
    "    print(f'the size of city_ct is {city_ct}')\n",
    "    print(f'the size of farm_ct is {farm_ct}')\n",
    "    print(f'the size of fire1_ct is {fire1_ct}')\n",
    "    print(f'the size of fire2_ct is {fire2_ct}')\n",
    "else:\n",
    "    print('not the same size')\n",
    "    \n",
    "total_sum=sum_nofire+sum_fire\n",
    "print('total_sum:',total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b09ebe02-ad30-424b-80ff-350edc906abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createTVTS(start,total_img:int,step=1,\n",
    "              valid_frac=0.15,test_frac=0.15,\n",
    "              replace=False,verbose=True,debug=False):\n",
    "    '''\n",
    "    Creates three lists for a train/validation/test split of \n",
    "    numbered files, such as patches previously made from \n",
    "    a larger image to be used in convolutional neural network \n",
    "    workflows.\n",
    "    \n",
    "    The training fraction of the output is the remainder of\n",
    "    the sum of the validation fraction and the testing fraction:\n",
    "    \n",
    "    train_frac = 1 - (valid_frac + test_frac)\n",
    "    \n",
    "    Default splits are:\n",
    "        0.7    = 1 - (   .15     +    .15 )\n",
    "    \n",
    "    Please ensure that you have a reasonable split amongst these\n",
    "    three groups.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >start\n",
    "    starting number for the image patches\n",
    "    \n",
    "    >total_img\n",
    "    serves both as total size of images in the patch set\n",
    "    \n",
    "    >step\n",
    "    defaults to 1, the step size in creating a list of numbers\n",
    "    \n",
    "    >valid_frac\n",
    "    the fraction of the numbers that will be split into the\n",
    "    validation set. Please make the number between 0 and 1\n",
    "    \n",
    "    >train_frac\n",
    "    the fraction of the numbers that will be split into the\n",
    "    training set. Please make the number between 0 and 1\n",
    "    \n",
    "    >replace\n",
    "    since this function is splitting the numbers, replace defaults\n",
    "    to False\n",
    "    \n",
    "    >verbose\n",
    "    runs a line of code to check that the splitting was successful\n",
    "    \n",
    "    >debug\n",
    "    helpful print statements to show you what step function is on.\n",
    "    defaults to not showing these statements\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >train_valid_test_tuple\n",
    "    a tuple of three lists, containing the train, valid, and\n",
    "    test list that when combined together are the same size as\n",
    "    the total_img value\n",
    "    \n",
    "    '''\n",
    "#     create list with each image's number\n",
    "#     there are `total_img` images each in the fire and nofire datasets\n",
    "    file_nums=np.arange(start,total_img,step)\n",
    "    if debug==True:\n",
    "        print(f'created initial list of size {total_img}')\n",
    "        \n",
    "#     create train fraction\n",
    "    train_frac=1-(valid_frac+test_frac)\n",
    "    if debug==True:\n",
    "        print(f'created train_fraction ({train_frac})')\n",
    "    \n",
    "#     create train, valid, and test splits    \n",
    "    trains = np.random.choice(file_nums,\n",
    "                              size=int(total_img * train_frac),\n",
    "                              replace=False)\n",
    "    if debug==True:\n",
    "        print('created train list')\n",
    "    \n",
    "    valids = np.random.choice(np.setdiff1d(file_nums, trains),\n",
    "                              size=int(total_img * valid_frac),\n",
    "                              replace=False)\n",
    "    if debug==True:\n",
    "        print('created validation list')\n",
    "    \n",
    "    tests = np.random.choice(np.setdiff1d(file_nums, np.concatenate((trains, valids))),\n",
    "                             size=int(total_img * test_frac),\n",
    "                             replace=False)\n",
    "    if debug==True:\n",
    "        print('created test list')\n",
    "    \n",
    "    # tests=list(set(file_nums)-set(trains))\n",
    "\n",
    "    if verbose==True:\n",
    "        print(f'The size of train ({len(trains)}), validation ({len(valids)}), and tests ({len(tests)}) together is {len(trains)+len(valids)+len(tests)}')\n",
    "        if debug==True:\n",
    "            print('printed size of train, validation, and test')\n",
    "            \n",
    "    train_valid_test_tuple=(trains,tests,valids)\n",
    "    if debug==True:\n",
    "         print('created tuple of train, validation, and test')\n",
    "    \n",
    "    return train_valid_test_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23452a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created initial list of size 19836\n",
      "created train_fraction (0.7)\n",
      "created train list\n",
      "created validation list\n",
      "created test list\n",
      "The size of train (13885), validation (2975), and tests (2975) together is 19835\n",
      "printed size of train, validation, and test\n",
      "created tuple of train, validation, and test\n",
      "13885\n",
      "2975\n",
      "2975\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# run function\n",
    "# total_sum is defined in a cell above\n",
    "train_valid_test_tuple=createTVTS(start=0,total_img=total_sum,\\\n",
    "                                  step=1,verbose=True,\\\n",
    "                                  debug=True)\n",
    "# train_valid_test_tuple\n",
    "\n",
    "# sanity checks\n",
    "trains=train_valid_test_tuple[0]\n",
    "valids=train_valid_test_tuple[1]\n",
    "tests=train_valid_test_tuple[2]\n",
    "\n",
    "print(len(trains))\n",
    "print(len(valids))\n",
    "print(len(tests))\n",
    "\n",
    "print(set(trains) & set(valids) & set(tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "373461e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15641, 14998, 10468, ..., 17694,  9970,  2793])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9aff638a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert list of integers to list of strings\n",
    "# important for moving files in next step\n",
    "trains=[str(i) for i in trains]\n",
    "valids=[str(i) for i in valids]\n",
    "tests=[str(i) for i in tests]\n",
    "\n",
    "type(trains[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355e2bf-3a46-46a6-b0a6-cb556700b64f",
   "metadata": {},
   "source": [
    "As a reminder: the images are in four folders. Though all images have names corresponding to their folder, they have similar numbers across the folders. For example, the folder `patch_nofire_farm` has images with the pattern `patch_nofire_farm.XXXX.tif`. Images from the `patch_nofire_city` folder have the pattern `patch_nofire_city.XXXX.tif`, and the numbers from the `_farm` folder are repeated in the `_city` folder. I want the numbers to be different so that, as the file counting function above demonstrates:\n",
    "* The images from `city` are numbered `0` through `7523`\n",
    "* The images from `farm` are numbered `7524` through `9918`\n",
    "* And so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef2129-ec56-491d-bac7-ea938881dfdf",
   "metadata": {},
   "source": [
    "the size of city_ct is 7524  \n",
    "the size of farm_ct is 2394  \n",
    "the size of fire1_ct is 7524  \n",
    "the size of fire2_ct is 2394"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e4097-60a3-4a55-a477-eaa8458932b8",
   "metadata": {},
   "source": [
    "Rename the images following the pattern described above and enumerated below:\n",
    "\n",
    "* `city` = 0 to 7523\n",
    "* `farm` = 7524 to 9916\n",
    "* `fire1` = 9917 to 17441\n",
    "* `fire2` = 17442 to 19836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ea4cffe-21af-4b68-816d-97cede901a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to specify the filenumbers\n",
    "\n",
    "def resetFileNumbers(directory: str, prefix: str, start: int = 0):\n",
    "    '''\n",
    "    Resets the numbering in filenames \n",
    "    in the provided directory.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >directory\n",
    "    the directory where the files are located\n",
    "    \n",
    "    >prefix\n",
    "    the prefix part of the filename that will remain\n",
    "    \n",
    "    >start\n",
    "    the starting number for the file numbering\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    renames files in-place, no further output\n",
    "    \n",
    "    ----\n",
    "    Example:\n",
    "    >>directory='./files'\n",
    "    >>prefix='file_'\n",
    "    >>reset_file_numbers(directory=directory,prefix=prefix, start=2)\n",
    "    >>file_2\n",
    "    >>file_3\n",
    "    >>file_4\n",
    "    '''\n",
    "\n",
    "    # create a list of all the files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # filter only the files with the prefix provided\n",
    "    files = [f for f in files if f.startswith(prefix)]\n",
    "\n",
    "    # sort the files by their numerical suffix\n",
    "#     files.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
    "    files.sort(key=lambda x: int(''.join(filter(str.isdigit, x))) if any(char.isdigit() for char in x) else 0)\n",
    "\n",
    "    \n",
    "    # rename the files with the new numbering\n",
    "    for i, filename in enumerate(files):\n",
    "        new_filename = prefix + str(i + start) + os.path.splitext(filename)[1]\n",
    "        os.rename(os.path.join(directory, filename),\n",
    "                  os.path.join(directory, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01a90efc-0f7f-43fa-96f0-2f8366fd2f18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # test the function\n",
    "\n",
    "# test_dir='/Users/sra/temp'\n",
    "# test_prefix='patch_'\n",
    "test_start=0\n",
    "\n",
    "# resetFileNumbers(directory=test_dir,\n",
    "#                  prefix=test_prefix,\n",
    "#                  start=test_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7fb65a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the size of city_ct is 7524\n",
    "# the size of farm_ct is 2394\n",
    "# the size of fire1_ct is 7524\n",
    "# the size of fire2_ct is 2394"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b991c5",
   "metadata": {},
   "source": [
    "Rename the images following the pattern described above and enumerated below:\n",
    "\n",
    "* `city` = 0 to 7523\n",
    "* `farm` = 7524 to 9917\n",
    "* `fire1` = 9918 to 17442\n",
    "* `fire2` = 17443 to 19835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94545a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetFileNumbers(directory: str, prefix: str, start: int = 0):\n",
    "    '''\n",
    "    Resets the numbering in filenames \n",
    "    in the provided directory.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >directory\n",
    "    the directory where the files are located\n",
    "    \n",
    "    >prefix\n",
    "    the prefix part of the filename that will remain\n",
    "    \n",
    "    >start\n",
    "    the starting number for the file numbering\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    renames files in-place, no further output\n",
    "    \n",
    "    ----\n",
    "    Example:\n",
    "    >>directory='./files'\n",
    "    >>prefix='file_'\n",
    "    >>reset_file_numbers(directory=directory,prefix=prefix, start=2)\n",
    "    >>file_2\n",
    "    >>file_3\n",
    "    >>file_4\n",
    "    '''\n",
    "\n",
    "    # create a list of all the files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # filter only the files with the prefix provided\n",
    "    files = [f for f in files if f.startswith(prefix)]\n",
    "\n",
    "    # sort the files by their numerical suffix\n",
    "    files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "    # rename the files with the new numbering\n",
    "    for i, filename in enumerate(files):\n",
    "        new_filename = prefix + str(i + start) + os.path.splitext(filename)[1]\n",
    "        shutil.move(os.path.join(directory, filename),\n",
    "                  os.path.join(directory, new_filename))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "648f779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# city images are already named appropriately \n",
    "# they start at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0dce003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# farm\n",
    "# directory_='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/farm'\n",
    "directory_='./patches/_patch_jpg/farm'\n",
    "\n",
    "prefix_='patch_nofire_farm_'\n",
    "start_=7524\n",
    "\n",
    "# destination_folder='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/city/flow_control_resetFileNumbers0to19835'\n",
    "# destination='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/farm'\n",
    "destination_folder='./patches/_patch_jpg/city/flow_control_resetFileNumbers0to19835'\n",
    "destination='./patches/_patch_jpg/farm'\n",
    "\n",
    "\n",
    "if not os.path.exists(destination_folder):\n",
    "    for dr,prf in zip([directory_], [prefix_]):\n",
    "        resetFileNumbers(directory=dr,prefix=prf,start=start_)\n",
    "        \n",
    "    # create the full path to the new folder\n",
    "    new_folder_path = os.path.join(destination, 'flow_control_resetFileNumbers0to19835')\n",
    "\n",
    "    # create the new folder if it doesn't already exist\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "        \n",
    "    # move the files to the new folder\n",
    "    for file in os.listdir(directory_):\n",
    "        if file.startswith(prefix_):\n",
    "            shutil.move(os.path.join(directory_, file), os.path.join(new_folder_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0ba65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fire1\n",
    "# directory_='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire1'\n",
    "directory_='./patches/_patch_jpg/fire1'\n",
    "\n",
    "prefix_='patch_fire_fire1_'\n",
    "start_=9918\n",
    "\n",
    "# destination_folder='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire1/flow_control_resetFileNumbers0to19835'\n",
    "# destination='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire1'\n",
    "destination_folder='./patches/_patch_jpg/fire1/flow_control_resetFileNumbers0to19835'\n",
    "destination='./patches/_patch_jpg/fire1'\n",
    "\n",
    "\n",
    "if not os.path.exists(destination_folder):\n",
    "    for dr,prf in zip([directory_], [prefix_]):\n",
    "        resetFileNumbers(directory=dr,prefix=prf,start=start_)\n",
    "        \n",
    "    # create the full path to the new folder\n",
    "    new_folder_path = os.path.join(destination, 'flow_control_resetFileNumbers0to19835')\n",
    "\n",
    "    # create the new folder if it doesn't already exist\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "        \n",
    "    # move the files to the new folder\n",
    "    for file in os.listdir(directory_):\n",
    "        if file.startswith(prefix_):\n",
    "            shutil.move(os.path.join(directory_, file), os.path.join(new_folder_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a451dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fire2\n",
    "# directory_='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2'\n",
    "directory_='./patches/_patch_jpg/fire2'\n",
    "prefix_='patch_fire_fire2_'\n",
    "start_=17442\n",
    "\n",
    "# destination_folder='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2/flow_control_resetFileNumbers0to19835'\n",
    "# destination='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2'\n",
    "destination_folder='./patches/_patch_jpg/fire2/flow_control_resetFileNumbers0to19835'\n",
    "destination='./patches/_patch_jpg/fire2'\n",
    "\n",
    "\n",
    "if not os.path.exists(destination_folder):\n",
    "    for dr,prf in zip([directory_], [prefix_]):\n",
    "        resetFileNumbers(directory=dr,prefix=prf,start=start_)\n",
    "        \n",
    "    # create the full path to the new folder\n",
    "    new_folder_path = os.path.join(destination, 'flow_control_resetFileNumbers0to19835')\n",
    "\n",
    "    # create the new folder if it doesn't already exist\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "        \n",
    "    # move the files to the new folder\n",
    "    for file in os.listdir(directory_):\n",
    "        if file.startswith(prefix_):\n",
    "            shutil.move(os.path.join(directory_, file), os.path.join(new_folder_path, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc319d-0018-4d16-b394-a68c37385302",
   "metadata": {},
   "source": [
    "### Moving the images to their corresponding training and validation locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9142b9d4",
   "metadata": {},
   "source": [
    "#### First, move the images to a nofire and fire folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e1da6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files_by_extension(source_folder, dest_folder, extension):\n",
    "    \"\"\"\n",
    "    Move all files with the specified extension from the source folder to the destination folder.\n",
    "    \n",
    "    Args:\n",
    "    - source_folder (str): The path to the source folder.\n",
    "    - dest_folder (str): The path to the destination folder.\n",
    "    - extension (str): The file extension to move, with or without the dot (e.g., '.txt' or 'txt').\n",
    "    \n",
    "    Returns:\n",
    "    - None: The function does not return anything, but raises an error if the source or destination folder \n",
    "    paths are invalid or if there are no files with the specified extension in the source folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the source folder exists\n",
    "    if not os.path.exists(source_folder):\n",
    "        raise ValueError(f\"The source folder {source_folder} does not exist.\")\n",
    "    \n",
    "    # Check if the destination folder exists; if not, create it\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "    \n",
    "    # Get a list of all files in the source folder with the specified extension\n",
    "    files_to_move = [f for f in os.listdir(source_folder) if f.endswith(extension)]\n",
    "    \n",
    "    # Raise an error if no files were found with the specified extension\n",
    "    if len(files_to_move) == 0:\n",
    "        raise ValueError(f\"No files with the extension {extension} were found in the source folder {source_folder}.\")\n",
    "    \n",
    "    # Move each file from the source folder to the destination folder\n",
    "    for file in files_to_move:\n",
    "        source_file_path = os.path.join(source_folder, file)\n",
    "        dest_file_path = os.path.join(dest_folder, file)\n",
    "        shutil.move(source_file_path, dest_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "598c0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/city'\n",
    "# dest='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/nofire'\n",
    "source='./patches/_patch_jpg/city'\n",
    "dest='./patches/_patch_jpg/nofire'\n",
    "\n",
    "move_files_by_extension(source_folder=source,dest_folder=dest,extension='.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e41796eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22728ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/farm/flow_control_resetFileNumbers0to19835'\n",
    "# dest='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/nofire'\n",
    "source='./patches/_patch_jpg/farm/flow_control_resetFileNumbers0to19835'\n",
    "dest='./patches/_patch_jpg/nofire'\n",
    "\n",
    "move_files_by_extension(source_folder=source,dest_folder=dest,extension='.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "614c9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fire1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc395fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire1/flow_control_resetFileNumbers0to19835'\n",
    "# dest='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire'\n",
    "source='./patches/_patch_jpg/fire1/flow_control_resetFileNumbers0to19835'\n",
    "dest='./patches/_patch_jpg/fire'\n",
    "\n",
    "move_files_by_extension(source_folder=source,dest_folder=dest,extension='.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fire2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88cbf95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2/flow_control_resetFileNumbers0to19835'\n",
    "# dest='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire'\n",
    "source='./patches/_patch_jpg/fire2/flow_control_resetFileNumbers0to19835'\n",
    "dest='./patches/_patch_jpg/fire'\n",
    "\n",
    "move_files_by_extension(source_folder=source,dest_folder=dest,extension='.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f50873e",
   "metadata": {},
   "source": [
    "##### Move the files based on train/valid/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "164bc6ce-8590-4a00-bb58-152f7d6db5c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def copyFileByNumber(source, dest, set_):\n",
    "    '''\n",
    "    Copies files from `source` to `dest` that have numbers \n",
    "    in their filename and that match any element in `set_` \n",
    "    list (either trains, valids, or tests).\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >source\n",
    "    source of files to be copied\n",
    "    \n",
    "    >dest\n",
    "    destination of files to be moved to\n",
    "    \n",
    "    >set_\n",
    "    specify either the training ('trains'), validation\n",
    "    ('valids') or test ('tests') set\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    copies files, no further output\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for filename in os.listdir(source):\n",
    "        # Get the number in the filename\n",
    "        file_num = \"\".join(filter(str.isdigit, filename))\n",
    "        # Check if the number is in the trains list\n",
    "        if file_num in set_:\n",
    "            # Copy the file to the destination folder\n",
    "            shutil.copy(os.path.join(source, filename), dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6187c0e8-feb9-44a1-aaa5-840d6f13b890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup loop for copyFileByNumber\n",
    "\n",
    "# dest_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/train/fire'\n",
    "# dest_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/train/nofire'\n",
    "# dest_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/validation/fire'\n",
    "# dest_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/validation/nofire'\n",
    "# dest_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/test/fire'\n",
    "# dest_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/test/nofire'\n",
    "\n",
    "dest_train_fire='./patches/_model_images/train/fire'\n",
    "dest_train_nofire='./patches/_model_images/train/nofire'\n",
    "dest_valid_fire='./patches/_model_images/validation/fire'\n",
    "dest_valid_nofire='./patches/_model_images/validation/nofire'\n",
    "dest_test_fire='./patches/_model_images/test/fire'\n",
    "dest_test_nofire='./patches/_model_images/test/nofire'\n",
    "\n",
    "# source_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire'\n",
    "# source_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/nofire'\n",
    "# source_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire'\n",
    "# source_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/nofire'\n",
    "# source_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire'\n",
    "# source_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/nofire'\n",
    "\n",
    "source_train_fire='./patches/_patch_jpg/fire'\n",
    "source_train_nofire='./patches/_patch_jpg/nofire'\n",
    "source_valid_fire='./patches/_patch_jpg/fire'\n",
    "source_valid_nofire='./patches/_patch_jpg/nofire'\n",
    "source_test_fire='./patches/_patch_jpg/fire'\n",
    "source_test_nofire='./patches/_patch_jpg/nofire'\n",
    "\n",
    "\n",
    "sources = [source_train_fire,\n",
    "          source_train_nofire,\n",
    "          source_valid_fire,\n",
    "          source_valid_nofire,\n",
    "          source_test_fire,\n",
    "          source_test_nofire]\n",
    "\n",
    "dests = [dest_train_fire,\n",
    "        dest_train_nofire,\n",
    "        dest_valid_fire,\n",
    "        dest_valid_nofire,\n",
    "        dest_test_fire,\n",
    "        dest_test_nofire]\n",
    "\n",
    "sets = [trains,\n",
    "        trains,\n",
    "        valids,\n",
    "        valids,\n",
    "        tests,\n",
    "        tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7a686691-4feb-4a75-ac73-2a6e8364d24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run function to move subsets of patches\n",
    "# flow control\n",
    "if filePresenceSumChecker(directory=dests[0],extension='.tif')==0:\n",
    "    for src,des,sts in zip(sources,dests,sets):\n",
    "        copyFileByNumber(source=src,dest=des,set_=sts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7dc0e411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created initial list of size 9918\n",
      "created train_fraction (0.7)\n",
      "created train list\n",
      "created validation list\n",
      "created test list\n",
      "The size of train (6942), validation (1487), and tests (1487) together is 9916\n",
      "printed size of train, validation, and test\n",
      "created tuple of train, validation, and test\n",
      "6942\n",
      "1487\n",
      "1487\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# fire\n",
    "# run function\n",
    "# total_sum is defined in a cell above\n",
    "train_valid_test_tuple=createTVTS(start=0,total_img=9918,\\\n",
    "                                  step=1,verbose=True,\\\n",
    "                                  debug=True)\n",
    "# train_valid_test_tuple\n",
    "\n",
    "# sanity checks\n",
    "fire_trains=train_valid_test_tuple[0]\n",
    "fire_valids=train_valid_test_tuple[1]\n",
    "fire_tests=train_valid_test_tuple[2]\n",
    "\n",
    "print(len(fire_trains))\n",
    "print(len(fire_valids))\n",
    "print(len(fire_tests))\n",
    "\n",
    "print(set(fire_trains) & set(fire_valids) & set(fire_tests))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f69205-9b3b-4c3f-9217-c9c45ee88dab",
   "metadata": {},
   "source": [
    "Create list of numbers for the second fraction of images. The numbers range from 9919 to 19835."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fcc0414-1edf-428f-b024-0586b94ef235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_list(start, end, train_frac, valid_frac, test_frac):\n",
    "    '''\n",
    "    Splits a list of numbers from start to end into training, validation, and\n",
    "    test sets using the specified fractions.\n",
    "    \n",
    "    Args:\n",
    "    start (int): The starting number in the list.\n",
    "    end (int): The ending number in the list.\n",
    "    train_frac (float): The fraction of numbers to put in the training set.\n",
    "    valid_frac (float): The fraction of numbers to put in the validation set.\n",
    "    test_frac (float): The fraction of numbers to put in the test set.\n",
    "    \n",
    "    Returns:\n",
    "    A tuple of three lists, containing the train, valid, and test list that \n",
    "    when combined together are the same size as the range from start to end.\n",
    "    '''\n",
    "    \n",
    "    # Create list with each number from start to end\n",
    "    nums = np.arange(start, end+1)\n",
    "    \n",
    "    # Calculate the number of elements to put in each set\n",
    "    train_size = int(len(nums) * train_frac)\n",
    "    valid_size = int(len(nums) * valid_frac)\n",
    "    test_size = len(nums) - train_size - valid_size\n",
    "    \n",
    "    # Use np.random.choice to split the numbers into sets\n",
    "    train_nums = np.random.choice(nums, size=train_size, replace=False)\n",
    "    nums = np.setdiff1d(nums, train_nums)\n",
    "    valid_nums = np.random.choice(nums, size=valid_size, replace=False)\n",
    "    test_nums = np.setdiff1d(nums, valid_nums)\n",
    "    \n",
    "    # Return the tuple of lists\n",
    "    return (train_nums, valid_nums, test_nums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae07790f-208e-40cf-bc8b-e28919d31dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,valid,test=split_list(start=9918,end=19835,\n",
    "                            train_frac=0.7,\n",
    "                            valid_frac=0.15,\n",
    "                            test_frac=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98fb4416-77c8-435a-aeaf-ca56e092be84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train: 6942\n",
      "valid: 1487\n",
      "test:  1489\n",
      "sum: 9918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_len=len(train)\n",
    "valid_len=len(valid)\n",
    "test_len=len(test)\n",
    "\n",
    "print(f'''\n",
    "train: {len(train)}\n",
    "valid: {len(valid)}\n",
    "test:  {len(test)}\n",
    "sum: {train_len+valid_len+test_len}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec551c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup loop for copyFileByNumber\n",
    "\n",
    "# source_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire'\n",
    "# source_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/nofire'\n",
    "# source_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire'\n",
    "# source_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/nofire'\n",
    "# source_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire'\n",
    "# source_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/nofire'\n",
    "\n",
    "source_train_fire='./patches/_patch_jpg/fire'\n",
    "source_train_nofire='./patches/_patch_jpg/nofire'\n",
    "source_valid_fire='./patches/_patch_jpg/fire'\n",
    "source_valid_nofire='./patches/_patch_jpg/nofire'\n",
    "source_test_fire='./patches/_patch_jpg/fire'\n",
    "source_test_nofire='./patches/_patch_jpg/nofire'\n",
    "\n",
    "# dest_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/train/fire'\n",
    "# dest_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/train/nofire'\n",
    "# dest_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/validation/fire'\n",
    "# dest_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/validation/nofire'\n",
    "# dest_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/test/fire'\n",
    "# dest_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/test/nofire'\n",
    "\n",
    "dest_train_fire='./patches/_model_images/train/fire'\n",
    "dest_train_nofire='./patches/_model_images/train/nofire'\n",
    "dest_valid_fire='./patches/_model_images/validation/fire'\n",
    "dest_valid_nofire='./patches/_model_images/validation/nofire'\n",
    "dest_test_fire='./patches/_model_images/test/fire'\n",
    "dest_test_nofire='./patches/_model_images/test/nofire'\n",
    "\n",
    "sources = [source_train_fire,\n",
    "          source_train_nofire,\n",
    "          source_valid_fire,\n",
    "          source_valid_nofire,\n",
    "          source_test_fire,\n",
    "          source_test_nofire]\n",
    "\n",
    "dests = [dest_train_fire,\n",
    "        dest_train_nofire,\n",
    "        dest_valid_fire,\n",
    "        dest_valid_nofire,\n",
    "        dest_test_fire,\n",
    "        dest_test_nofire]\n",
    "\n",
    "sets = [trains,\n",
    "        trains,\n",
    "        valids,\n",
    "        valids,\n",
    "        tests,\n",
    "        tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e66dab8-f72e-4261-9ee8-7cba81ea086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files_by_number(source_dir, dest_dir, numbers_list, extension, prefix):\n",
    "    '''\n",
    "    Takes a source directory, destination directory,\n",
    "    list of numbers, an extension, and a prefix, and uses \n",
    "    all of that to move files that exactly match the\n",
    "    resultant filename from the source to the directory.\n",
    "    '''\n",
    "    for filename in os.listdir(source_dir):\n",
    "        if filename.endswith(extension) and filename.startswith(prefix):\n",
    "            file_number = int(filename[len(prefix):-len(extension)])\n",
    "            if file_number in numbers_list:\n",
    "                source_path = os.path.join(source_dir, filename)\n",
    "                dest_path = os.path.join(dest_dir, filename)\n",
    "                shutil.copyfile(source_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8487615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test function\n",
    "\n",
    "source='/Users/sra/temp'\n",
    "dest='/Users/sra/temp2'\n",
    "set_=[0,1,2]\n",
    "\n",
    "copy_files_by_number(source_dir=source,\n",
    "                    dest_dir=dest,\n",
    "                    numbers_list=set_,\n",
    "                    extension='.jpg',\n",
    "                    prefix='patch_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042df842-623d-43fc-9bba-6ae1b18c52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup loop for copyFileByNumber\n",
    "\n",
    "# dest_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/train/fire'\n",
    "# dest_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/train/nofire'\n",
    "# dest_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/validation/fire'\n",
    "# dest_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/validation/nofire'\n",
    "# dest_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/test/fire'\n",
    "# dest_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_model_images/test/nofire'\n",
    "\n",
    "dest_train_fire='./patches/_model_images/train/fire'\n",
    "dest_train_nofire='./patches/_model_images/train/nofire'\n",
    "dest_valid_fire='./patches/_model_images/validation/fire'\n",
    "dest_valid_nofire='./patches/_model_images/validation/nofire'\n",
    "dest_test_fire='./patches/_model_images/test/fire'\n",
    "dest_test_nofire='./patches/_model_images/test/nofire'\n",
    "\n",
    "# source_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire'\n",
    "# source_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/nofire'\n",
    "# source_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire'\n",
    "# source_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/nofire'\n",
    "# source_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire'\n",
    "# source_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/nofire'\n",
    "\n",
    "source_train_fire='./patches/_patch_jpg/fire'\n",
    "source_train_nofire='./patches/_patch_jpg/nofire'\n",
    "source_valid_fire='./patches/_patch_jpg/fire'\n",
    "source_valid_nofire='./patches/_patch_jpg/nofire'\n",
    "source_test_fire='./patches/_patch_jpg/fire'\n",
    "source_test_nofire='./patches/_patch_jpg/nofire'\n",
    "\n",
    "sources = [source_train_fire,\n",
    "          source_train_nofire,\n",
    "          source_valid_fire,\n",
    "          source_valid_nofire,\n",
    "          source_test_fire,\n",
    "          source_test_nofire]\n",
    "\n",
    "dests = [dest_train_fire,\n",
    "        dest_train_nofire,\n",
    "        dest_valid_fire,\n",
    "        dest_valid_nofire,\n",
    "        dest_test_fire,\n",
    "        dest_test_nofire]\n",
    "\n",
    "sets = [trains,\n",
    "        trains,\n",
    "        valids,\n",
    "        valids,\n",
    "        tests,\n",
    "        tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f68c16a-1068-46ed-8e05-807a6be6d4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fileDeleter(source:str, extension:str='.tif'):\n",
    "    '''\n",
    "    Deletes files with the provided extension from the source directory.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >source\n",
    "    the directory where the files are located\n",
    "    \n",
    "    >extension\n",
    "    defaults to '.tif', but this will ensure you only delete\n",
    "    certain files that have the specified extension\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    deletes files in-place, no further output\n",
    "    '''\n",
    "    \n",
    "    # loop over each file from the source directory\n",
    "    for filename in os.listdir(source):\n",
    "        \n",
    "        # check if the file is the provided `ext` (extension)\n",
    "        if filename.endswith(extension):\n",
    "            \n",
    "            # delete the file\n",
    "            os.remove(os.path.join(source, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2f03e2e2-0644-4d96-927f-8e0fe667f089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup for loop\n",
    "\n",
    "# inputPath_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "# inputPath_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "# inputPath_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "# inputPath_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "# inputPath_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "# inputPath_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "inputPath_train_fire='./patches/train/fire'\n",
    "inputPath_train_nofire='./patches/train/nofire'\n",
    "inputPath_valid_fire='./patches/validation/fire'\n",
    "inputPath_valid_nofire='./patches/validation/nofire'\n",
    "inputPath_test_fire='./patches/test/fire'\n",
    "inputPath_test_nofire='./patches/test/nofire'\n",
    "\n",
    "inputPaths=[inputPath_train_fire,\n",
    "            inputPath_train_nofire,\n",
    "            inputPath_valid_fire,\n",
    "            inputPath_valid_nofire,\n",
    "            inputPath_test_fire,\n",
    "            inputPath_test_nofire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cdb963db-be52-4ba4-a1d3-0f338b1e63e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# flow control\n",
    "if filePresenceSumChecker(directory=inputPath_train_fire,extension='.tif')>0:\n",
    "    for inp in (inputPaths):\n",
    "        fileDeleter(source=inp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
