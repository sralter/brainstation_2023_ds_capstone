{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537a66da-b2a3-4e9a-af40-8a90530ca548",
   "metadata": {},
   "source": [
    "# Welcome  \n",
    "\n",
    "Notebook Author: Samuel Alter  \n",
    "Notebook Subject: Capstone Project - Image Analysis\n",
    "\n",
    "BrainStation Winter 2023: Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a309895-d206-43f0-ba7f-21a35fa580ee",
   "metadata": {},
   "source": [
    "This notebook is for running my satellite images through deep learning networks. The images have been pre-processed in a separate notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df329c1a-b0f0-4278-b3cf-017e24f143b1",
   "metadata": {},
   "source": [
    "The goal is to find a pre-trained CNN to adapt to our specific use-case of finding insights about wildfire-prone landscapes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821271c8-f172-477e-b748-fc081a45fed4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5317015-1fc0-4ad5-b52c-612855b18144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecbfa3-8add-4bab-a5da-429c1cdba0a7",
   "metadata": {},
   "source": [
    "### Split all 7760 images in to `train` and `test` splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "febf5979-579c-407c-a413-f460119a603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5432\n",
      "2328\n",
      "The size of train and tests together is 7760\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# create list with each image's number\n",
    "# there are 7760 images each in the fire and nofire datasets\n",
    "file_nums=np.arange(0,7760,1)\n",
    "\n",
    "# create variables for the train and valids sizes\n",
    "train_size=0.7\n",
    "# test_size=1-train_size\n",
    "\n",
    "# create train and test splits\n",
    "trains=np.random.choice(file_nums,\n",
    "                        size=(int(7760*train_size)),\n",
    "                        replace=False)\n",
    "\n",
    "valids=list(set(file_nums)-set(trains))\n",
    "\n",
    "# sanity checks\n",
    "print(len(trains))\n",
    "print(len(valids))\n",
    "print(f'The size of train and valids together is \\\n",
    "{len(trains)+len(valids)}')\n",
    "print(set(trains) & set(valids))\n",
    "\n",
    "# good, that all matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b7985ba5-f344-42fc-b9ec-a8b8b9309f41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert list of integers to list of strings\n",
    "# important for moving files in next step\n",
    "trains=[str(i) for i in trains]\n",
    "valids=[str(i) for i in valids]\n",
    "\n",
    "type(trains[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeec780-3924-4593-b22d-eaa12209064b",
   "metadata": {},
   "source": [
    "#### Run these cells to move the images to their corresponding training and validation locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b30cf17f-2a3e-4787-979e-48d5f4742fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # fire\n",
    "# # train\n",
    "# # items to move: 5432\n",
    "\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# def copy_files_by_number(source, dest, trains):\n",
    "#     \"\"\"\n",
    "#     Copies files from `source` to `dest` that have numbers in their filename\n",
    "#     that match any element in `trains` list.\n",
    "#     \"\"\"\n",
    "#     for filename in os.listdir(source):\n",
    "#         # Get the number in the filename\n",
    "#         file_num = \"\".join(filter(str.isdigit, filename))\n",
    "#         # Check if the number is in the trains list\n",
    "#         if file_num in trains:\n",
    "#             # Copy the file to the destination folder\n",
    "#             shutil.copy(os.path.join(source, filename), dest)\n",
    "\n",
    "# source = '/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire'\n",
    "# dest = '/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "\n",
    "# copy_files_by_number(source=source,dest=dest,trains=trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dac8b405-1917-4e1e-87b2-27405f233765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # fire\n",
    "# # valids\n",
    "# # items to move: 2328\n",
    "\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# def copy_files_by_number(source, dest, valids):\n",
    "#     \"\"\"\n",
    "#     Copies files from `source` to `dest` that have numbers in their filename\n",
    "#     that match any element in `valids` list.\n",
    "#     \"\"\"\n",
    "#     for filename in os.listdir(source):\n",
    "#         # Get the number in the filename\n",
    "#         file_num = \"\".join(filter(str.isdigit, filename))\n",
    "#         # Check if the number is in the valids list\n",
    "#         if file_num in valids:\n",
    "#             # Copy the file to the destination folder\n",
    "#             shutil.copy(os.path.join(source, filename), dest)\n",
    "\n",
    "# source = '/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire'\n",
    "# dest = '/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "\n",
    "# copy_files_by_number(source=source,dest=dest,valids=valids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3b4d4bd1-2f12-41e6-a302-a3a9c045e6ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # nofire\n",
    "# # train\n",
    "# # items to move: 5432\n",
    "\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# def copy_files_by_number(source, dest, trains):\n",
    "#     \"\"\"\n",
    "#     Copies files from `source` to `dest` that have numbers in their filename\n",
    "#     that match any element in `trains` list.\n",
    "#     \"\"\"\n",
    "#     for filename in os.listdir(source):\n",
    "#         # Get the number in the filename\n",
    "#         file_num = \"\".join(filter(str.isdigit, filename))\n",
    "#         # Check if the number is in the trains list\n",
    "#         if file_num in trains:\n",
    "#             # Copy the file to the destination folder\n",
    "#             shutil.copy(os.path.join(source, filename), dest)\n",
    "\n",
    "# source = '/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire'\n",
    "# dest = '/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "\n",
    "# copy_files_by_number(source=source,dest=dest,trains=trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d390e3c3-0c4d-4b03-b334-5ad6d5a428f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nofire\n",
    "# # valids\n",
    "# # items to move: 2328\n",
    "\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# def copy_files_by_number(source, dest, valids):\n",
    "#     \"\"\"\n",
    "#     Copies files from `source` to `dest` that have numbers in their filename\n",
    "#     that match any element in `valids` list.\n",
    "#     \"\"\"\n",
    "#     for filename in os.listdir(source):\n",
    "#         # Get the number in the filename\n",
    "#         file_num = \"\".join(filter(str.isdigit, filename))\n",
    "#         # Check if the number is in the valids list\n",
    "#         if file_num in valids:\n",
    "#             # Copy the file to the destination folder\n",
    "#             shutil.copy(os.path.join(source, filename), dest)\n",
    "\n",
    "# source = '/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire'\n",
    "# dest = '/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "\n",
    "# copy_files_by_number(source=source,dest=dest,valids=valids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1200a66-7f84-4234-ac6c-14a64dfd051a",
   "metadata": {},
   "source": [
    "### Basic `ImageDataGenerator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93cb7a7-d7fe-4d51-9d7a-32fcf093750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from\n",
    "# https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
    "\n",
    "# import `ImageDataGenerator` to help facilitate \n",
    "# loading images directly from our computer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Specify the dimensions for the target preprocess image size\n",
    "height = 128 \n",
    "width = 128\n",
    "channels = 3\n",
    "\n",
    "# instantiate training image data generator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2) # set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir, # same directory as training data\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f72c2d-8be6-45a0-b615-a3929fe869d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/psmith/data_sources/images/monkeys/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m validation_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Specify where the images should be loaded from,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# as well as some additional attributes:\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m train_generator\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/psmith/data_sources/images/monkeys/train/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrgb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m validation_generator\u001b[38;5;241m=\u001b[39mvalidation_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/psmith/data_sources/images/monkeys/validation/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m                                                  target_size\u001b[38;5;241m=\u001b[39m(height,width),\n\u001b[1;32m     24\u001b[0m                                                  color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     25\u001b[0m                                                  batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     26\u001b[0m                                                  class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/deeplearning/lib/python3.8/site-packages/keras/preprocessing/image.py:976\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    899\u001b[0m                         directory,\n\u001b[1;32m    900\u001b[0m                         target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m                         subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    912\u001b[0m                         interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    913\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \n\u001b[1;32m    915\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;124;03m          and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 976\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m      \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m      \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/deeplearning/lib/python3.8/site-packages/keras/preprocessing/image.py:394\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    392\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[1;32m    393\u001b[0m   kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDirectoryIterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_data_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/deeplearning/lib/python3.8/site-packages/keras_preprocessing/image/directory_iterator.py:115\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m    114\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    117\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/psmith/data_sources/images/monkeys/train/'"
     ]
    }
   ],
   "source": [
    "# # Create validation image data generator\n",
    "# # Only apply rescaling to our validation data\n",
    "# validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# # Specify where the images should be loaded from,\n",
    "# # as well as some additional attributes:\n",
    "# train_generator=train_datagen.flow_from_directory('/Users/psmith/data_sources/images/monkeys/train/',\n",
    "#                                                  target_size=(height,width),\n",
    "#                                                  color_mode='rgb',\n",
    "#                                                  batch_size=32,\n",
    "#                                                  class_mode='categorical')\n",
    "\n",
    "# validation_generator=validation_datagen.flow_from_directory('/Users/psmith/data_sources/images/monkeys/validation/',\n",
    "#                                                  target_size=(height,width),\n",
    "#                                                  color_mode='rgb',\n",
    "#                                                  batch_size=32,\n",
    "#                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b84a129-907c-4a56-9458-a03ae495499a",
   "metadata": {},
   "source": [
    "### `VGG19`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e04b6955-3c7b-4077-b05e-4a7ba50e9f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "height = 128 \n",
    "width = 128\n",
    "channels = 3\n",
    "\n",
    "res_model = VGG19(weights='imagenet',\n",
    "                   include_top=False,\n",
    "                   input_shape=(height,width,channels))\n",
    "res_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1bbfb8-3f64-4917-9588-b509186a3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the layers in the base model\n",
    "for layer in res_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8802ca94-48e7-49d3-906b-e38c3ea122d0",
   "metadata": {},
   "source": [
    "### `ResNet50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1fda0-2ecb-425a-a53f-35afe78673fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
