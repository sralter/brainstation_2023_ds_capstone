{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537a66da-b2a3-4e9a-af40-8a90530ca548",
   "metadata": {},
   "source": [
    "# Welcome  \n",
    "\n",
    "Notebook Author: Samuel Alter  \n",
    "Notebook Subject: Capstone Project - Image Analysis\n",
    "\n",
    "BrainStation Winter 2023: Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a309895-d206-43f0-ba7f-21a35fa580ee",
   "metadata": {},
   "source": [
    "This notebook is for running my images through deep learning networks. The images have been pre-processed in a separate notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df329c1a-b0f0-4278-b3cf-017e24f143b1",
   "metadata": {},
   "source": [
    "The goal is to find a pre-trained CNN to adapt to our specific use-case of finding insights about wildfire-prone landscapes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821271c8-f172-477e-b748-fc081a45fed4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5317015-1fc0-4ad5-b52c-612855b18144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a60b361-9678-4e5f-bd10-f6be599008ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import `ImageDataGenerator` to help facilitate \n",
    "# loading images directly from our computer\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16962640-3aef-45f1-b13f-53c87bea73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the dimensions for the target preprocess image size\n",
    "\n",
    "height = 128 \n",
    "width = 128\n",
    "channels = 3\n",
    "\n",
    "# Create training image data generator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create validation image data generator\n",
    "# Only apply rescaling to our validation data\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Specify where the images should be loaded from,\n",
    "# as well as some additional attributes:\n",
    "train_generator=train_datagen.flow_from_directory('/Users/psmith/data_sources/images/monkeys/train/',\n",
    "                                                 target_size=(height,width),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "validation_generator=validation_datagen.flow_from_directory('/Users/psmith/data_sources/images/monkeys/validation/',\n",
    "                                                 target_size=(height,width),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04b6955-3c7b-4077-b05e-4a7ba50e9f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 107s 1us/step\n",
      "80150528/80134624 [==============================] - 107s 1us/step\n",
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "height = 128 \n",
    "width = 128\n",
    "channels = 3\n",
    "\n",
    "res_model = VGG19(weights='imagenet',\n",
    "                   include_top=False,\n",
    "                   input_shape=(height,width,channels))\n",
    "res_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1bbfb8-3f64-4917-9588-b509186a3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the layers in the base model\n",
    "for layer in res_model.layers:\n",
    "    layer.trainable = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
