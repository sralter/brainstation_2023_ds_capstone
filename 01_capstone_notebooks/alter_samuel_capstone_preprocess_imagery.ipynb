{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afe2082",
   "metadata": {},
   "source": [
    "# Welcome  \n",
    "\n",
    "Notebook Author: Samuel Alter  \n",
    "Notebook Subject: Capstone Project - Preprocess Imagery\n",
    "\n",
    "BrainStation Winter 2023: Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22225f7-5492-4286-adb0-8fa32a548cf9",
   "metadata": {},
   "source": [
    "This notebook is for processing the satellite into chunks for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617c7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ab51f-13d0-4c24-8761-dd7bc85ec925",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Clip raster to polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798acac-b2e2-40a2-a76e-217059b245b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr\n",
    "\n",
    "# Define the input raster and polygon mask\n",
    "input_raster = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722.tif\"\n",
    "mask = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/perimeters_sm/santa_monica_fire_perimeters_fire_valid.shp\"\n",
    "\n",
    "# Open the input raster and polygon mask\n",
    "raster_ds = gdal.Open(input_raster)\n",
    "mask_ds = ogr.Open(mask)\n",
    "\n",
    "# Get the mask layer\n",
    "mask_lyr = mask_ds.GetLayer()\n",
    "\n",
    "# Get the extent of the mask layer\n",
    "mask_extent = mask_lyr.GetExtent()\n",
    "\n",
    "# Set the output file name and format\n",
    "output_file = \"path/to/clipped_raster.tif\"\n",
    "output_format = \"GTiff\"\n",
    "\n",
    "# Set the output file resolution\n",
    "output_res = raster_ds.GetGeoTransform()[1]\n",
    "\n",
    "# Define the output file size\n",
    "output_width = int((mask_extent[1] - mask_extent[0]) / output_res)\n",
    "output_height = int((mask_extent[3] - mask_extent[2]) / output_res)\n",
    "\n",
    "# Define the warp options\n",
    "warp_options = gdal.WarpOptions(cutlineDSName=mask, cropToCutline=True, dstSRS=raster_ds.GetProjection(), outputBounds=mask_extent, xRes=output_res, yRes=output_res, width=output_width, height=output_height)\n",
    "\n",
    "# Call the gdal.Warp() function to clip the raster\n",
    "clipped_raster_ds = gdal.Warp(output_file, raster_ds, options=warp_options)\n",
    "\n",
    "# Save clipped raster to a shapefile\n",
    "output_shp = \"path/to/clipped_raster.shp\"\n",
    "gdal.VectorTranslate(output_shp, clipped_raster_ds, format=\"ESRI Shapefile\")\n",
    "\n",
    "# Save clipped raster to a GeoJSON\n",
    "output_geojson = \"path/to/clipped_raster.geojson\"\n",
    "gdal.VectorTranslate(output_geojson, clipped_raster_ds, format=\"GeoJSON\")\n",
    "\n",
    "# Clean up\n",
    "raster_ds = None\n",
    "mask_ds = None\n",
    "clipped_raster_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23256ed2-3407-4ff5-a0c0-5702da487a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr\n",
    "\n",
    "# Define the input raster and polygon mask\n",
    "input_raster = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722.tif\"\n",
    "mask = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/perimeters_sm/santa_monica_fire_perimeters_fire_valid.shp\"\n",
    "\n",
    "# Open the input raster and polygon mask\n",
    "raster_ds = gdal.Open(input_raster)\n",
    "mask_ds = ogr.Open(mask)\n",
    "\n",
    "# Get the mask layer\n",
    "mask_lyr = mask_ds.GetLayer()\n",
    "\n",
    "# Get the extent of the mask layer\n",
    "mask_extent = mask_lyr.GetExtent()\n",
    "\n",
    "# Set the output file name and format for GeoTIFF\n",
    "output_file_tif = \"path/to/clipped_raster.tif\"\n",
    "output_format_tif = \"GTiff\"\n",
    "\n",
    "# Set the output file name and format for GeoJSON\n",
    "output_file_geojson = \"path/to/clipped_raster.geojson\"\n",
    "output_format_geojson = \"GeoJSON\"\n",
    "\n",
    "# Set the output file resolution\n",
    "output_res = raster_ds.GetGeoTransform()[1]\n",
    "\n",
    "# Define the output file size\n",
    "output_width = int((mask_extent[1] - mask_extent[0]) / output_res)\n",
    "output_height = int((mask_extent[3] - mask_extent[2]) / output_res)\n",
    "\n",
    "# Define the warp options\n",
    "warp_options = gdal.WarpOptions(cutlineDSName=mask, cropToCutline=True, dstSRS=raster_ds.GetProjection(), outputBounds=mask_extent, xRes=output_res, yRes=output_res, width=output_width, height=output_height)\n",
    "\n",
    "# Call the gdal.Warp() function to clip the raster\n",
    "clipped_raster_ds = gdal.Warp('', raster_ds, options=warp_options)\n",
    "\n",
    "# Save clipped raster to GeoTIFF\n",
    "output_tif = \"path/to/clipped_raster.tif\"\n",
    "gdal.Translate(output_tif, clipped_raster_ds, format=output_format_tif)\n",
    "\n",
    "# Save clipped raster to GeoJSON\n",
    "output_geojson = \"path/to/clipped_raster.geojson\"\n",
    "gdal.Translate(output_file_geojson, clipped_raster_ds, format=output_format_geojson)\n",
    "\n",
    "# Save clipped raster to a shapefile\n",
    "output_shp = \"path/to/clipped_raster.shp\"\n",
    "gdal.VectorTranslate(output_shp, clipped_raster_ds, format=\"ESRI Shapefile\")\n",
    "\n",
    "# Clean up\n",
    "raster_ds = None\n",
    "mask_ds = None\n",
    "clipped_raster_ds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af8e27-b327-42c9-b65e-c86d10408814",
   "metadata": {},
   "source": [
    "## [Extrating Patches from Large Images ~~and Masks~~ for Semantic Segmentation](https://www.youtube.com/watch?v=7IL7LKSLb9I)\n",
    "\n",
    "Following this tutorial to convert my large fire/nofire images into patches for neural network analysis. The code block below is from this video, with some alterations to adapt it to my use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d314417-7d91-45a0-93de-d30e6264187c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from patchify import patchify\n",
    "import tifffile as tiff\n",
    "\n",
    "# large_image_stack_fire=tiff.imread('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_sm_fire.tif')\n",
    "\n",
    "large_image_stack_patch_fire=tiff.imread('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722/m_3411849_se_11_060_20180722_fire.tif')\n",
    "# large_image_stack_patch_fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14f55fc2-3190-47e8-a311-2403ca83bed9",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/loadsave.cpp:77: error: (-215:Assertion failed) pixels <= CV_IO_MAX_IMAGE_PIXELS in function 'validateInputImageSize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m output_location_fire\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722/patches_fire\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# read large_image_stack_test\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_tiff_fire\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m,img)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/loadsave.cpp:77: error: (-215:Assertion failed) pixels <= CV_IO_MAX_IMAGE_PIXELS in function 'validateInputImageSize'\n"
     ]
    }
   ],
   "source": [
    "# updated \n",
    "# https://stackoverflow.com/questions/68224588/problem-when-using-patchify-library-to-create-patches\n",
    "\n",
    "import cv2\n",
    "\n",
    "# filepaths\n",
    "target_tiff_fire=r'/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722/m_3411849_se_11_060_20180722_converted_fire.tif'\n",
    "output_location_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722/patches_fire'\n",
    "\n",
    "# read large_image_stack_test\n",
    "img = cv2.imread(target_tiff_fire)\n",
    "\n",
    "cv2.imshow('image',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed44680e-d00b-41fc-91f3-e53c9ce668ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/loadsave.cpp:77: error: (-215:Assertion failed) pixels <= CV_IO_MAX_IMAGE_PIXELS in function 'validateInputImageSize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m output_location_fire\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722/patches_fire\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# read large_image_stack_test\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_tiff_fire\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m patches_img \u001b[38;5;241m=\u001b[39m patchify(img, (\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m3\u001b[39m), step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(patches_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/loadsave.cpp:77: error: (-215:Assertion failed) pixels <= CV_IO_MAX_IMAGE_PIXELS in function 'validateInputImageSize'\n"
     ]
    }
   ],
   "source": [
    "patches_img = patchify(img, (128,128,3), step=128)\n",
    "\n",
    "for i in range(patches_img.shape[0]):\n",
    "    for j in range(patches_img.shape[1]):\n",
    "        single_patch_img = patches_img[i, j, 0, :, :, :]\n",
    "        if not cv2.imwrite(output_location_fire + 'image_' + '_'+ str(i)+str(j)+'.jpg', single_patch_img):\n",
    "            raise Exception(\"Could not write the image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6489ba4e-9b52-4484-82af-5f76bd372c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "gis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
