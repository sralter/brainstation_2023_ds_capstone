{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afe2082",
   "metadata": {},
   "source": [
    "# Welcome  \n",
    "\n",
    "Notebook Author: Samuel Alter  \n",
    "Notebook Subject: Capstone Project - Preprocess Imagery\n",
    "\n",
    "BrainStation Winter 2023: Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22225f7-5492-4286-adb0-8fa32a548cf9",
   "metadata": {},
   "source": [
    "This notebook is for processing the satellite into chunks for modelling, and cleaning the files to ensure only square images are fed into the image analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf2e13-67ce-4af6-b325-a63e2ec0565e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "617c7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e2698-6c4c-4c4b-8b7b-d88dd2658abe",
   "metadata": {},
   "source": [
    "## Split all images in to `train` and `test` splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d87745d-bfa4-496d-a491-e299ba976532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for flow control. \n",
    "# If a file was already created in a folder,\n",
    "# then when put in an if statement, this function can prevent\n",
    "# actions from occurring.\n",
    "\n",
    "def filePresenceSumChecker(directory:str,extension:str,count=True,verbose=False):\n",
    "    '''\n",
    "    Checks the sum of all the files with a certain extension.\n",
    "    \n",
    "    Useful to see if a file move process has already been completed.\n",
    "    \n",
    "    ----\n",
    "    Inputs\n",
    "    \n",
    "    >directory\n",
    "    path to a folder to check if files are there\n",
    "    \n",
    "    >extension\n",
    "    user-specified extension to only count those files\n",
    "    \n",
    "    >verbose\n",
    "    option for the user to see how many files with the extension \n",
    "    is in the directory provided\n",
    "    \n",
    "    >count\n",
    "    option for the user to see the count of the files\n",
    "    \n",
    "    ----\n",
    "    Outputs\n",
    "    \n",
    "    >counter\n",
    "    gives the amount of files within the directory\n",
    "    '''\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    # get a list of all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # iterate through the files and check if any have the specified extension\n",
    "    for file in files:\n",
    "        if file.endswith(extension):\n",
    "            counter+=1\n",
    "                \n",
    "    if verbose==True:\n",
    "        print(f\"There are {counter} '{extension}' files within {directory}.\")\n",
    "\n",
    "    if count==True:\n",
    "        return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b09ebe02-ad30-424b-80ff-350edc906abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createTVTS(start,total_img:int,step=1,\n",
    "              valid_frac=0.15,test_frac=0.15,\n",
    "              replace=False,verbose=True,debug=False):\n",
    "    '''\n",
    "    Creates three lists for a train/validation/test split of \n",
    "    numbered files, such as patches previously made from \n",
    "    a larger image to be used in convolutional neural network \n",
    "    workflows.\n",
    "    \n",
    "    The training fraction of the output is the remainder of\n",
    "    the sum of the validation fraction and the testing fraction:\n",
    "    \n",
    "    train_frac = 1 - (valid_frac + test_frac)\n",
    "    \n",
    "    Default splits are:\n",
    "        0.7    = 1 - (   .15     +    .15 )\n",
    "    \n",
    "    Please ensure that you have a reasonable split amongst these\n",
    "    three groups.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >start\n",
    "    starting number for the image patches\n",
    "    \n",
    "    >total_img\n",
    "    serves both as total size of images in the patch set\n",
    "    \n",
    "    >step\n",
    "    defaults to 1, the step size in creating a list of numbers\n",
    "    \n",
    "    >valid_frac\n",
    "    the fraction of the numbers that will be split into the\n",
    "    validation set. Please make the number between 0 and 1\n",
    "    \n",
    "    >train_frac\n",
    "    the fraction of the numbers that will be split into the\n",
    "    training set. Please make the number between 0 and 1\n",
    "    \n",
    "    >replace\n",
    "    since this function is splitting the numbers, replace defaults\n",
    "    to False\n",
    "    \n",
    "    >verbose\n",
    "    runs a line of code to check that the splitting was successful\n",
    "    \n",
    "    >debug\n",
    "    helpful print statements to show you what step function is on.\n",
    "    defaults to not showing these statements\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >train_valid_test_tuple\n",
    "    a tuple of three lists, containing the train, valid, and\n",
    "    test list that when combined together are the same size as\n",
    "    the total_img value\n",
    "    \n",
    "    '''\n",
    "#     create list with each image's number\n",
    "#     there are `total_img` images each in the fire and nofire datasets\n",
    "    file_nums=np.arange(start,total_img,step)\n",
    "    if debug==True:\n",
    "        print(f'created initial list of size {total_img}')\n",
    "        \n",
    "#     create train fraction\n",
    "    train_frac=1-(valid_frac+test_frac)\n",
    "    if debug==True:\n",
    "        print(f'created train_fraction ({train_frac})')\n",
    "    \n",
    "#     create train, valid, and test splits    \n",
    "    trains = np.random.choice(file_nums,\n",
    "                              size=int(total_img * train_frac),\n",
    "                              replace=False)\n",
    "    if debug==True:\n",
    "        print('created train list')\n",
    "    \n",
    "    valids = np.random.choice(np.setdiff1d(file_nums, trains),\n",
    "                              size=int(total_img * valid_frac),\n",
    "                              replace=False)\n",
    "    if debug==True:\n",
    "        print('created validation list')\n",
    "    \n",
    "    tests = np.random.choice(np.setdiff1d(file_nums, np.concatenate((trains, valids))),\n",
    "                             size=int(total_img * test_frac),\n",
    "                             replace=False)\n",
    "    if debug==True:\n",
    "        print('created test list')\n",
    "    \n",
    "    # tests=list(set(file_nums)-set(trains))\n",
    "\n",
    "    if verbose==True:\n",
    "        print(f'The size of train ({len(trains)}), validation ({len(valids)}), and tests ({len(tests)}) together is {len(trains)+len(valids)+len(tests)}')\n",
    "        if debug==True:\n",
    "            print('printed size of train, validation, and test')\n",
    "            \n",
    "    train_valid_test_tuple=(trains,tests,valids)\n",
    "    if debug==True:\n",
    "         print('created tuple of train, validation, and test')\n",
    "    \n",
    "    return train_valid_test_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b9f349be-f706-4d76-86bf-de50e5058a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created initial list of size 7760\n",
      "created train_fraction (0.7)\n",
      "created train list\n",
      "created validation list\n",
      "created test list\n",
      "The size of train (5432), validation (1164), and tests (1164) together is 7760\n",
      "printed size of train, validation, and test\n",
      "created tuple of train, validation, and test\n",
      "5432\n",
      "1164\n",
      "1164\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# run function\n",
    "train_valid_test_tuple=createTVTS(start=0,total_img=7760,\\\n",
    "                                  step=1,verbose=True,\\\n",
    "                                  debug=True)\n",
    "# train_valid_test_tuple\n",
    "\n",
    "# sanity checks\n",
    "trains=train_valid_test_tuple[0]\n",
    "valids=train_valid_test_tuple[1]\n",
    "tests=train_valid_test_tuple[2]\n",
    "\n",
    "print(len(trains))\n",
    "print(len(valids))\n",
    "print(len(tests))\n",
    "\n",
    "print(set(trains) & set(valids) & set(tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2a97ec11-634e-417b-803f-f274c305ee88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1179, 5283, 7319, ..., 4356, 5760, 3943])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b9963231-e06f-4fc4-816d-7aae699b8a37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert list of integers to list of strings\n",
    "# important for moving files in next step\n",
    "trains=[str(i) for i in trains]\n",
    "valids=[str(i) for i in valids]\n",
    "tests=[str(i) for i in tests]\n",
    "\n",
    "type(trains[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc319d-0018-4d16-b394-a68c37385302",
   "metadata": {},
   "source": [
    "### Move the images to their corresponding training and validation locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "164bc6ce-8590-4a00-bb58-152f7d6db5c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def copyFileByNumber(source, dest, set_):\n",
    "    '''\n",
    "    Copies files from `source` to `dest` that have numbers \n",
    "    in their filename and that match any element in `set_` \n",
    "    list (either trains, valids, or tests).\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >source\n",
    "    source of files to be copied\n",
    "    \n",
    "    >dest\n",
    "    destination of files to be moved to\n",
    "    \n",
    "    >set_\n",
    "    specify either the training ('trains'), validation\n",
    "    ('valids') or test ('tests') set\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    copies files, no further output\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for filename in os.listdir(source):\n",
    "        # Get the number in the filename\n",
    "        file_num = \"\".join(filter(str.isdigit, filename))\n",
    "        # Check if the number is in the trains list\n",
    "        if file_num in set_:\n",
    "            # Copy the file to the destination folder\n",
    "            shutil.copy(os.path.join(source, filename), dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ecbe557-9208-4669-afa4-6f1c99229a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filePresenceSumChecker(directory:str,extension:str,verbose=False):\n",
    "    '''\n",
    "    Checks the sum of all the files with a certain extension.\n",
    "    \n",
    "    Useful to see if a file move process has already been completed.\n",
    "    \n",
    "    ----\n",
    "    Inputs\n",
    "    \n",
    "    >directory\n",
    "    path to a folder to check if files are there\n",
    "    \n",
    "    >extension\n",
    "    user-specified extension to only count those files\n",
    "    \n",
    "    ----\n",
    "    Outputs\n",
    "    \n",
    "    >counter\n",
    "    gives the amount of files within the directory\n",
    "    '''\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    # get a list of all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # iterate through the files and check if any have the specified extension\n",
    "    for file in files:\n",
    "        if file.endswith(extension):\n",
    "            counter+=1\n",
    "                \n",
    "    if verbose==True:\n",
    "        print(f\"There are {counter} '{extension}' files within {directory}.\")\n",
    "\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6187c0e8-feb9-44a1-aaa5-840d6f13b890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup loop for copyFileByNumber\n",
    "\n",
    "source_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire'\n",
    "source_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire'\n",
    "source_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire'\n",
    "source_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire'\n",
    "source_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire'\n",
    "source_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire'\n",
    "\n",
    "\n",
    "dest_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "dest_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "dest_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "dest_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "dest_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "dest_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "\n",
    "sources = [source_train_fire,\n",
    "          source_train_nofire,\n",
    "          source_valid_fire,\n",
    "          source_valid_nofire,\n",
    "          source_test_fire,\n",
    "          source_test_nofire]\n",
    "\n",
    "dests = [dest_train_fire,\n",
    "        dest_train_nofire,\n",
    "        dest_valid_fire,\n",
    "        dest_valid_nofire,\n",
    "        dest_test_fire,\n",
    "        dest_test_nofire]\n",
    "\n",
    "sets = [trains,\n",
    "        trains,\n",
    "        valids,\n",
    "        valids,\n",
    "        tests,\n",
    "        tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7a686691-4feb-4a75-ac73-2a6e8364d24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run function to move subsets of patches\n",
    "# flow control\n",
    "if filePresenceSumChecker(directory=dests[0],extension='.tif')==0:\n",
    "    for src,des,sts in zip(sources,dests,sets):\n",
    "        copyFileByNumber(source=src,dest=des,set_=sts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea6bcb8-7877-493e-acf8-c23afa3fc165",
   "metadata": {},
   "source": [
    "### Rename files and change to proper format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbb71fd-617d-4845-a231-087d7fb691ba",
   "metadata": {},
   "source": [
    "Convert filenames from `patch_fire.X.tif` to `patch_fire_X.tif`, where X is a number with one or more digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "224caa0d-be99-4865-a6f9-580d9e61eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileRenamer(source:str, prefix:str,extension='.tif'):\n",
    "    '''\n",
    "    Renames files to the format provided by the user.\n",
    "    It can help clean an image format to one that can be\n",
    "    read by modules like Tensorflow.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >source\n",
    "    the directory where the files are located\n",
    "    \n",
    "    >prefix\n",
    "    the base part of the filename that will remain\n",
    "    \n",
    "    >extension\n",
    "    defaults to '.tif', but this will ensure you only rename\n",
    "    certain files that have the specified extension\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    renames files in-place, no further output\n",
    "    '''\n",
    "\n",
    "    # loop over each file from the source directory\n",
    "    for filename in os.listdir(source):\n",
    "        \n",
    "        # check if the file is the provided `ext` (extension)\n",
    "        if filename.endswith(extension):\n",
    "            \n",
    "            # split the filename into base and extension\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            \n",
    "            # split the base into the prefix and number parts\n",
    "            prefix, number = base.split('.', 1)\n",
    "            \n",
    "            # create the new filename with the desired format\n",
    "            new_filename = f'{prefix}_{number}{ext}'\n",
    "            \n",
    "            # rename the file\n",
    "            os.rename(os.path.join(source, filename), \n",
    "                      os.path.join(source, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f56bedc5-7295-4939-8e8b-67fb8ccd846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a for loop to rename all the files\n",
    "\n",
    "source_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "source_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "source_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "source_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "source_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "source_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "\n",
    "sources=[source_train_fire,\n",
    "        source_train_nofire,\n",
    "        source_valid_fire,\n",
    "        source_valid_nofire,\n",
    "        source_test_fire,\n",
    "        source_test_nofire]\n",
    " \n",
    "# flow control\n",
    "if filePresenceSumChecker(directory=source_train_fire,extension='.tif')<0:\n",
    "    for src in sources:    \n",
    "        fileRenamer(source=src,prefix='patch_fire')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256756f3-ee18-448d-846c-26a41f7cf665",
   "metadata": {},
   "source": [
    "Convert .tif images to .jpg for `ImageDataGenerator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "36f26cb0-b0ba-4ff0-aca7-30209fb478ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageConverter(inputPath, outputPath, oldExtension='.tif',newExtension='.jpg',fileType='JPEG',verbose=False):\n",
    "    '''\n",
    "    Iterates through a directory of (default) .tif files and \n",
    "    converts them to (default) .jpg format using Pillow library.\n",
    "\n",
    "    Requires an input directory path \n",
    "    and an output directory path as strings.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >inputPath\n",
    "    string path to where the inputs are located\n",
    "    \n",
    "    >outputPath\n",
    "    string path to where the outputs will be located\n",
    "    '''\n",
    "\n",
    "    # create the output directory if it doesn't exist\n",
    "    # os.makedirs(outputPath, exist_ok=True)\n",
    "\n",
    "    # iterate through all files in the input directory\n",
    "    for file_name in os.listdir(inputPath):\n",
    "        if file_name.endswith(oldExtension):\n",
    "            # construct the input and output file paths\n",
    "            input_path = os.path.join(inputPath, file_name)\n",
    "            output_path = os.path.join(outputPath, \n",
    "                                       file_name.replace(oldExtension,\n",
    "                                                         newExtension))\n",
    "\n",
    "            # load the image\n",
    "            # https://stackoverflow.com/questions/40751523/how-do-you-read-a-32-bit-tiff-image-in-python\n",
    "            img = cv2.imread(input_path,-1)\n",
    "            \n",
    "            # convert to RGB format if necessary\n",
    "            if img.shape[2] == 1:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            elif img.shape[2] == 4:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "\n",
    "            # Save the image as a .jpg file\n",
    "            cv2.imwrite(output_path, img, [int(cv2.IMWRITE_JPEG_QUALITY), 90])\n",
    "            \n",
    "            if verbose==True:\n",
    "                print(f\"Conversion complete: {input_path} -> {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "06bf3ab4-7a7b-4f54-84b4-9a532bd4ad86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "extension = '.jpg'\n",
    "\n",
    "filePresenceSumChecker(directory=directory,extension=extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "41262501-a201-41d7-b6d7-39efe1e43932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for loop\n",
    "\n",
    "inputPath_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "inputPath_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "inputPath_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "inputPath_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "inputPath_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "inputPath_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "\n",
    "outputPath_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "outputPath_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "outputPath_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "outputPath_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "outputPath_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "outputPath_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "\n",
    "inputPaths=[inputPath_train_fire,\n",
    "            inputPath_train_nofire,\n",
    "            inputPath_valid_fire,\n",
    "            inputPath_valid_nofire,\n",
    "            inputPath_test_fire,\n",
    "            inputPath_test_nofire]\n",
    "\n",
    "outputPaths=[outputPath_train_fire,\n",
    "            outputPath_train_nofire,\n",
    "            outputPath_valid_fire,\n",
    "            outputPath_valid_nofire,\n",
    "            outputPath_test_fire,\n",
    "            outputPath_test_nofire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ea6eb6eb-2d80-4a89-becd-1d5c3daecdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow control\n",
    "if filePresenceSumChecker(directory=outputPath_train_fire,extension='.jpg')==0:\n",
    "    for inp,outp in zip(inputPaths,outputPaths):\n",
    "        imageConverter(inputPath=inp,outputPath=outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "93800cdf-66c9-40a2-894e-f059c7257d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePresenceSumChecker(directory='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire',\n",
    "                      extension='.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6f68c16a-1068-46ed-8e05-807a6be6d4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fileDeleter(source:str, extension:str='.tif'):\n",
    "    '''\n",
    "    Deletes files with the provided extension from the source directory.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >source\n",
    "    the directory where the files are located\n",
    "    \n",
    "    >extension\n",
    "    defaults to '.tif', but this will ensure you only delete\n",
    "    certain files that have the specified extension\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    deletes files in-place, no further output\n",
    "    '''\n",
    "    \n",
    "    # loop over each file from the source directory\n",
    "    for filename in os.listdir(source):\n",
    "        \n",
    "        # check if the file is the provided `ext` (extension)\n",
    "        if filename.endswith(extension):\n",
    "            \n",
    "            # delete the file\n",
    "            os.remove(os.path.join(source, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2f03e2e2-0644-4d96-927f-8e0fe667f089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup for loop\n",
    "\n",
    "inputPath_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "inputPath_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "inputPath_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "inputPath_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "inputPath_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "inputPath_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "inputPaths=[inputPath_train_fire,\n",
    "            inputPath_train_nofire,\n",
    "            inputPath_valid_fire,\n",
    "            inputPath_valid_nofire,\n",
    "            inputPath_test_fire,\n",
    "            inputPath_test_nofire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cdb963db-be52-4ba4-a1d3-0f338b1e63e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# flow control\n",
    "if filePresenceSumChecker(directory=inputPath_train_fire,extension='.tif')>0:\n",
    "    for inp in (inputPaths):\n",
    "        fileDeleter(source=inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2285dd83-7db9-4119-9f80-e358f3fb1441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/validation/nofire'\n",
    "\n",
    "input_path='/Users/sra/temp'\n",
    "output_path='/Users/sra/temp3'\n",
    "\n",
    "if filePresenceSumChecker(directory=output_path,extension='.jpg') != 0:\n",
    "    separateNonSquareImages(input_path=input_path,output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "055cd17e-1ff8-4c8e-a529-d5b73e84c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveNonSquareImages(source_folder, destination_folder):\n",
    "    '''\n",
    "    Checks to see if any image in the source folder does not have\n",
    "    square dimensions (e.g. 29x128 is not square, 128x128 is)\n",
    "    \n",
    "    ----\n",
    "    Inputs\n",
    "    \n",
    "    >source_folder\n",
    "    the source of the images to be checked\n",
    "    \n",
    "    >destination_folder\n",
    "    where the non-square images should be relocated to\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Create destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    \n",
    "    # get a list of all image files in the source folder\n",
    "    image_files = [f for f in os.listdir(source_folder) if \\\n",
    "                   f.endswith('.jpg') or \\\n",
    "                   f.endswith('.jpeg') or \\\n",
    "                   f.endswith('.png')]\n",
    "    \n",
    "    for file_name in image_files:\n",
    "        # open the image using PIL\n",
    "        img = Image.open(os.path.join(source_folder, file_name))\n",
    "        \n",
    "        # check if image is square\n",
    "        if img.size[0] != img.size[1]:\n",
    "            # move the image to the destination folder\n",
    "            shutil.move(os.path.join(source_folder, file_name), os.path.join(destination_folder, file_name))\n",
    "            # # delete the non-square image from the source folder\n",
    "            # os.remove(os.path.join(source_folder, file_name))\n",
    "            \n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c392543-8dce-466a-bec3-557262105ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for loop\n",
    "\n",
    "inputPath_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "inputPath_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "inputPath_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "inputPath_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "inputPath_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "inputPath_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "destPath_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/train/fire'\n",
    "destPath_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/train/nofire'\n",
    "destPath_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/validation/fire'\n",
    "destPath_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/validation/nofire'\n",
    "destPath_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/test/fire'\n",
    "destPath_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/test/nofire'\n",
    "\n",
    "inputPaths=[inputPath_train_fire,\n",
    "            inputPath_train_nofire,\n",
    "            inputPath_valid_fire,\n",
    "            inputPath_valid_nofire,\n",
    "            inputPath_test_fire,\n",
    "            inputPath_test_nofire]\n",
    "\n",
    "destPaths=[destPath_train_fire,\n",
    "          destPath_train_nofire,\n",
    "          destPath_valid_fire,\n",
    "          destPath_valid_nofire,\n",
    "          destPath_test_fire,\n",
    "          destPath_test_nofire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0fe7ef10-b436-4fad-9b15-5449901b38be",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_location='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/validation/nofire'\n",
    "\n",
    "if filePresenceSumChecker(directory=checked_location,extension='.jpg') == 0:\n",
    "    for inp,des in zip(inputPaths,destPaths):\n",
    "        moveNonSquareImages(source_folder=inp,destination_folder=des)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ab51f-13d0-4c24-8761-dd7bc85ec925",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Clip raster to polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798acac-b2e2-40a2-a76e-217059b245b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr\n",
    "\n",
    "# Define the input raster and polygon mask\n",
    "input_raster = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722.tif\"\n",
    "mask = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/perimeters_sm/santa_monica_fire_perimeters_fire_valid.shp\"\n",
    "\n",
    "# Open the input raster and polygon mask\n",
    "raster_ds = gdal.Open(input_raster)\n",
    "mask_ds = ogr.Open(mask)\n",
    "\n",
    "# Get the mask layer\n",
    "mask_lyr = mask_ds.GetLayer()\n",
    "\n",
    "# Get the extent of the mask layer\n",
    "mask_extent = mask_lyr.GetExtent()\n",
    "\n",
    "# Set the output file name and format\n",
    "output_file = \"path/to/clipped_raster.tif\"\n",
    "output_format = \"GTiff\"\n",
    "\n",
    "# Set the output file resolution\n",
    "output_res = raster_ds.GetGeoTransform()[1]\n",
    "\n",
    "# Define the output file size\n",
    "output_width = int((mask_extent[1] - mask_extent[0]) / output_res)\n",
    "output_height = int((mask_extent[3] - mask_extent[2]) / output_res)\n",
    "\n",
    "# Define the warp options\n",
    "warp_options = gdal.WarpOptions(cutlineDSName=mask, cropToCutline=True, dstSRS=raster_ds.GetProjection(), outputBounds=mask_extent, xRes=output_res, yRes=output_res, width=output_width, height=output_height)\n",
    "\n",
    "# Call the gdal.Warp() function to clip the raster\n",
    "clipped_raster_ds = gdal.Warp(output_file, raster_ds, options=warp_options)\n",
    "\n",
    "# Save clipped raster to a shapefile\n",
    "output_shp = \"path/to/clipped_raster.shp\"\n",
    "gdal.VectorTranslate(output_shp, clipped_raster_ds, format=\"ESRI Shapefile\")\n",
    "\n",
    "# Save clipped raster to a GeoJSON\n",
    "output_geojson = \"path/to/clipped_raster.geojson\"\n",
    "gdal.VectorTranslate(output_geojson, clipped_raster_ds, format=\"GeoJSON\")\n",
    "\n",
    "# Clean up\n",
    "raster_ds = None\n",
    "mask_ds = None\n",
    "clipped_raster_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23256ed2-3407-4ff5-a0c0-5702da487a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr\n",
    "\n",
    "# Define the input raster and polygon mask\n",
    "input_raster = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722.tif\"\n",
    "mask = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/perimeters_sm/santa_monica_fire_perimeters_fire_valid.shp\"\n",
    "\n",
    "# Open the input raster and polygon mask\n",
    "raster_ds = gdal.Open(input_raster)\n",
    "mask_ds = ogr.Open(mask)\n",
    "\n",
    "# Get the mask layer\n",
    "mask_lyr = mask_ds.GetLayer()\n",
    "\n",
    "# Get the extent of the mask layer\n",
    "mask_extent = mask_lyr.GetExtent()\n",
    "\n",
    "# Set the output file name and format for GeoTIFF\n",
    "output_file_tif = \"path/to/clipped_raster.tif\"\n",
    "output_format_tif = \"GTiff\"\n",
    "\n",
    "# Set the output file name and format for GeoJSON\n",
    "output_file_geojson = \"path/to/clipped_raster.geojson\"\n",
    "output_format_geojson = \"GeoJSON\"\n",
    "\n",
    "# Set the output file resolution\n",
    "output_res = raster_ds.GetGeoTransform()[1]\n",
    "\n",
    "# Define the output file size\n",
    "output_width = int((mask_extent[1] - mask_extent[0]) / output_res)\n",
    "output_height = int((mask_extent[3] - mask_extent[2]) / output_res)\n",
    "\n",
    "# Define the warp options\n",
    "warp_options = gdal.WarpOptions(cutlineDSName=mask, cropToCutline=True, dstSRS=raster_ds.GetProjection(), outputBounds=mask_extent, xRes=output_res, yRes=output_res, width=output_width, height=output_height)\n",
    "\n",
    "# Call the gdal.Warp() function to clip the raster\n",
    "clipped_raster_ds = gdal.Warp('', raster_ds, options=warp_options)\n",
    "\n",
    "# Save clipped raster to GeoTIFF\n",
    "output_tif = \"path/to/clipped_raster.tif\"\n",
    "gdal.Translate(output_tif, clipped_raster_ds, format=output_format_tif)\n",
    "\n",
    "# Save clipped raster to GeoJSON\n",
    "output_geojson = \"path/to/clipped_raster.geojson\"\n",
    "gdal.Translate(output_file_geojson, clipped_raster_ds, format=output_format_geojson)\n",
    "\n",
    "# Save clipped raster to a shapefile\n",
    "output_shp = \"path/to/clipped_raster.shp\"\n",
    "gdal.VectorTranslate(output_shp, clipped_raster_ds, format=\"ESRI Shapefile\")\n",
    "\n",
    "# Clean up\n",
    "raster_ds = None\n",
    "mask_ds = None\n",
    "clipped_raster_ds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af8e27-b327-42c9-b65e-c86d10408814",
   "metadata": {},
   "source": [
    "## [Extrating Patches from Large Images ~~and Masks~~ for Semantic Segmentation](https://www.youtube.com/watch?v=7IL7LKSLb9I)\n",
    "\n",
    "Following this tutorial to convert my large fire/nofire images into patches for neural network analysis. The code block below is from this video, with some alterations to adapt it to my use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d314417-7d91-45a0-93de-d30e6264187c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from patchify import patchify\n",
    "import tifffile as tiff\n",
    "\n",
    "# large_image_stack_fire=tiff.imread('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_sm_fire.tif')\n",
    "\n",
    "large_image_stack_patch_fire=tiff.imread('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/img_patch_fire2.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f55fc2-3190-47e8-a311-2403ca83bed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@347.904] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/grfmt_tiff.cpp (629) readData OpenCV TIFF: TIFFRGBAImageOK: Sorry, can not handle images with 32-bit samples\n"
     ]
    }
   ],
   "source": [
    "# updated \n",
    "# https://stackoverflow.com/questions/68224588/problem-when-using-patchify-library-to-create-patches\n",
    "\n",
    "import cv2\n",
    "\n",
    "# filepaths\n",
    "target_tiff_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/img_patch_fire2.tif'\n",
    "output_location_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches'\n",
    "\n",
    "# read large_image_stack_test\n",
    "img = cv2.imread(target_tiff_fire)\n",
    "\n",
    "# cv2.imshow('image',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed44680e-d00b-41fc-91f3-e53c9ce668ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/loadsave.cpp:77: error: (-215:Assertion failed) pixels <= CV_IO_MAX_IMAGE_PIXELS in function 'validateInputImageSize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m output_location_fire\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722/patches_fire\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# read large_image_stack_test\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_tiff_fire\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m patches_img \u001b[38;5;241m=\u001b[39m patchify(img, (\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m3\u001b[39m), step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(patches_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/loadsave.cpp:77: error: (-215:Assertion failed) pixels <= CV_IO_MAX_IMAGE_PIXELS in function 'validateInputImageSize'\n"
     ]
    }
   ],
   "source": [
    "patches_img = patchify(img, (128,128,3), step=128)\n",
    "\n",
    "for i in range(patches_img.shape[0]):\n",
    "    for j in range(patches_img.shape[1]):\n",
    "        single_patch_img = patches_img[i, j, 0, :, :, :]\n",
    "        if not cv2.imwrite(output_location_fire + 'image_' + '_'+ str(i)+str(j)+'.jpg', single_patch_img):\n",
    "            raise Exception(\"Could not write the image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6489ba4e-9b52-4484-82af-5f76bd372c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ce976-06da-4f90-b9cc-121df77a06b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6092d7-67cc-4d76-8dd0-aea688fa6eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
