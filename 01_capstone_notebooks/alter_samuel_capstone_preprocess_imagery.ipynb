{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afe2082",
   "metadata": {},
   "source": [
    "# Welcome  \n",
    "\n",
    "Notebook Author: Samuel Alter  \n",
    "Notebook Subject: Capstone Project - Preprocess Imagery\n",
    "\n",
    "BrainStation Winter 2023: Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22225f7-5492-4286-adb0-8fa32a548cf9",
   "metadata": {},
   "source": [
    "This notebook is for processing the satellite into tiles or 'patches' for modelling, and cleaning the files to ensure only square images are fed into the image analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf2e13-67ce-4af6-b325-a63e2ec0565e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617c7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e2698-6c4c-4c4b-8b7b-d88dd2658abe",
   "metadata": {},
   "source": [
    "## Split all images in to `train` and `test` splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52945d-cff0-4954-9f40-6a08bc04c000",
   "metadata": {},
   "source": [
    "### First, create a function for flow control. If a file was already created in a folder, then when put in an if statement, this function can prevent such actions from occurring. Its also just a handy function to check how many files are in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc0d172-293f-44b9-b799-4f4865a23db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filePresenceSumChecker(directory:str,extension:str,count=True,verbose=False):\n",
    "    '''\n",
    "    Checks the sum of all the files with a certain extension.\n",
    "    \n",
    "    Useful to see if a file move process has already been completed.\n",
    "    \n",
    "    ----\n",
    "    Inputs\n",
    "    \n",
    "    >directory\n",
    "    path to a folder to check if files are there\n",
    "    \n",
    "    >extension\n",
    "    user-specified extension to only count those files\n",
    "    \n",
    "    >verbose\n",
    "    option for the user to see how many files with the extension \n",
    "    is in the directory provided\n",
    "    \n",
    "    >count\n",
    "    option for the user to see the count of the files\n",
    "    \n",
    "    ----\n",
    "    Outputs\n",
    "    \n",
    "    >counter\n",
    "    gives the amount of files within the directory\n",
    "    '''\n",
    "    \n",
    "    counter=0\n",
    "    \n",
    "    # get a list of all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # iterate through the files and check if any have the specified extension\n",
    "    for file in files:\n",
    "        if file.endswith(extension):\n",
    "            counter+=1\n",
    "                \n",
    "    if verbose==True:\n",
    "        print(f\"There are {counter} '{extension}' files within {directory}.\")\n",
    "\n",
    "    if count==True:\n",
    "        return counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a57ff7-e015-4e9a-aee6-6d5c325dcc15",
   "metadata": {
    "tags": []
   },
   "source": [
    "Determine how many individual patch images are in the full patch dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7245f78-e7fe-443e-8b22-f41d12bd8482",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same size\n",
      "the size of city_ct is 7761\n",
      "the size of farm_ct is 2496\n",
      "the size of fire1_ct is 7761\n",
      "the size of fire2_ct is 2496\n"
     ]
    }
   ],
   "source": [
    "# setup paths\n",
    "farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_farm'\n",
    "city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_city'\n",
    "fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire1'\n",
    "fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire2'\n",
    "\n",
    "# save counts\n",
    "farm_ct=filePresenceSumChecker(directory=farm,extension='.tif')\n",
    "city_ct=filePresenceSumChecker(directory=city,extension='.tif')\n",
    "fire1_ct=filePresenceSumChecker(directory=fire1,extension='.tif')\n",
    "fire2_ct=filePresenceSumChecker(directory=fire2,extension='.tif')\n",
    "\n",
    "# sum fire patch counts together and nofire patch counts together\n",
    "sum_nofire=farm_ct+city_ct\n",
    "sum_fire=fire1_ct+fire2_ct\n",
    "\n",
    "# check if the sums are the same\n",
    "if sum_nofire==sum_nofire:\n",
    "    print('same size')\n",
    "    print(f'the size of city_ct is {city_ct}')\n",
    "    print(f'the size of farm_ct is {farm_ct}')\n",
    "    print(f'the size of fire1_ct is {fire1_ct}')\n",
    "    print(f'the size of fire2_ct is {fire2_ct}')\n",
    "else:\n",
    "    print('not the same size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340aea25-dfa3-4afe-b023-4642855c2729",
   "metadata": {},
   "source": [
    "The size of the image patches are the same per category, effectively building a labeled dataset with $50\\%$ images being from fire areas and $50\\%$ from nofire areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3363457-b4d1-4786-be47-14905ab04e04",
   "metadata": {},
   "source": [
    "The images are in four folders. Though all images have names corresponding to their folder, they have similar numbers across the folders. For example, the folder `patch_nofire_farm` has images with the pattern `patch_nofire_farm.XXXX.tif`. Images from the `patch_nofire_city` folder have the pattern `patch_nofire_city.XXXX.tif`, and the numbers from the `_farm` folder are repeated in the `_city` folder. I want the numbers to be different so that, as the file counting function above demonstrates:\n",
    "* The images from `city` are numbered `0` through `7761`\n",
    "* The images from `farm` are numbered `7762` through `10257`\n",
    "* And so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a102303-7744-475d-bf06-97926a84f574",
   "metadata": {},
   "source": [
    "### Rename the files to remove the period between the `_farm`/`_city`/etc. and `XXXX`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9ba731d-9c41-4f44-86f8-f9533016e202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fileRenamer(source:str, prefix:str,extension='.tif',verbose=False):\n",
    "    '''\n",
    "    Renames files to the format provided by the user.\n",
    "    It can help clean an image format to one that can be\n",
    "    read by modules like Tensorflow.\n",
    "    \n",
    "    Note: code will break if there are no files with a number\n",
    "    suffix separated by a period. Put the function in a flow\n",
    "    control loop first.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >source\n",
    "    the directory where the files are located\n",
    "    \n",
    "    >prefix\n",
    "    the base part of the filename that will remain\n",
    "    \n",
    "    >extension\n",
    "    defaults to '.tif', but this will ensure you only rename\n",
    "    certain files that have the specified extension\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    renames files in-place, no further output\n",
    "    \n",
    "    ----\n",
    "    Example:\n",
    "    >>source='/patch_nofire_farm.0.tif'\n",
    "    >>fileRenamer(source=source,prefix='patch_nofire_farm',extension='.tif')\n",
    "    >>patch_nofire_farm_testing_0.tif\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # loop over each file from the source directory\n",
    "    for filename in os.listdir(source):\n",
    "        if verbose==True:\n",
    "            print('filename:',filename)\n",
    "        \n",
    "        # check if the file is the provided `ext` (extension)\n",
    "        if filename.endswith(extension):\n",
    "            \n",
    "            # split the filename into base and extension\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            if verbose==True:\n",
    "                print('base:',base)\n",
    "                print('ext:',ext)\n",
    "            \n",
    "            # split the base into the prefix and number parts\n",
    "            prefix, number = base.split('.', 1)\n",
    "            if verbose==True:\n",
    "                print('prefix:',prefix)\n",
    "                print('number:',number)\n",
    "            \n",
    "            # create the new filename with the desired format\n",
    "            new_filename = f'{prefix}_{number}{ext}'\n",
    "            if verbose==True:\n",
    "                print('new_filename:',new_filename)\n",
    "            \n",
    "            # rename the file\n",
    "            os.rename(os.path.join(source, filename), \n",
    "                      os.path.join(source, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "616ceba9-18f9-462c-b9c3-1e2c399f706e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing renaming function\n",
    "# directory='/Users/sra/temp/'\n",
    "# prefix_='patch_nofire_city'\n",
    "\n",
    "# fileRenamer(source=directory,prefix=prefix_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "13401471-6792-45bf-b899-09168efc5101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write function to check if files have already been renamed\n",
    "# this is for flow control\n",
    "\n",
    "def checkFileString(directory_path, file_string):\n",
    "    '''\n",
    "    Takes a directory and string and checks if the string is\n",
    "    included in any of the filenames within the directory.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >directory_path\n",
    "    User-specified path to look for the filenames\n",
    "    \n",
    "    >file_string\n",
    "    User-specified string that the function will look for\n",
    "    '''\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if file_string in filename:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee92ef7c-ae32-4225-ad85-fa02b5e96586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup lists\n",
    "# to run renaming function\n",
    "\n",
    "city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_city'\n",
    "farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_farm'\n",
    "fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire1'\n",
    "fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire2'\n",
    "\n",
    "sources=[city,farm,#nofire\n",
    "        fire1,fire2]#fire\n",
    "\n",
    "prefix_city='patch_nofire_city'\n",
    "prefix_farm='patch_nofire_farm'\n",
    "prefix_fire1='patch_nofire_fire1'\n",
    "prefix_fire2='patch_nofire_fire2'\n",
    "\n",
    "prefixes=[prefix_city,prefix_farm,\n",
    "         prefix_fire1,prefix_fire2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb7a2506-dbc2-4c7d-8a3d-bc1039a38693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run fileRenamer on all the patches:\n",
    "# city #nofire\n",
    "# farm #nofire\n",
    "# fire1 #fire\n",
    "# fire2 #fire\n",
    "\n",
    "# setup directory for flow control file string checker function\n",
    "directory='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_city'\n",
    "\n",
    "if checkFileString(directory_path=directory,file_string='patch_nofire_city_') == False:\n",
    "    for src,pref in zip(sources,prefixes):\n",
    "        fileRenamer(source=src,prefix=pref,extension='.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ae14d-43af-4a60-a84c-f0134a913ce1",
   "metadata": {},
   "source": [
    "Checking the filenames shows that they have been changed to swap the `.` for a `_`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6706d513-7d15-4ba5-a602-295e8973cc36",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b434efe-0378-4d60-a44e-ed12de16f60e",
   "metadata": {},
   "source": [
    "Now I need to remove the non-square images from the folders because the point-creation tool (see geoanalysis and report) did not make points for the images that are on the margin of the four areas (`city`, `farm`, `fire1`, `fire2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca8921-b41a-4bf6-9396-eaf69586c49f",
   "metadata": {},
   "source": [
    "This needs to happen before I rename the images because the numbers corresponding to the images need to correspond to the geographic dataset. In other words, the ideal situation would be that point `18` in the geographic dataset corresponds to the exact location of image `18`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43720973-6003-4e3d-aec5-b73daac59d2c",
   "metadata": {},
   "source": [
    "First, though, the photos need to be converted from `.tif` to `.jpg`. This will be achieved through a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df81bd9-864e-4ca8-add5-2d59635640d6",
   "metadata": {},
   "source": [
    "### Convert `.tif` to `.jpg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "43442ea0-9f8a-430e-9968-cb859bf3f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageConverter(inputPath, outputPath, oldExtension='.tif',newExtension='.jpg',fileType='JPEG',verbose=False):\n",
    "    '''\n",
    "    Iterates through a directory of (default) .tif files and \n",
    "    converts them to (default) .jpg format using the Pillow library.\n",
    "    \n",
    "    The images will be sent to a new folder.\n",
    "\n",
    "    Requires an input directory path \n",
    "    and an output directory path as strings.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >inputPath\n",
    "    string path to where the inputs are located\n",
    "    \n",
    "    >outputPath\n",
    "    string path to where the outputs will be located\n",
    "    '''\n",
    "\n",
    "    # create the output directory if it doesn't exist\n",
    "    # os.makedirs(outputPath, exist_ok=True)\n",
    "\n",
    "    # iterate through all files in the input directory\n",
    "    for file_name in os.listdir(inputPath):\n",
    "        if file_name.endswith(oldExtension):\n",
    "            # construct the input and output file paths\n",
    "            input_path = os.path.join(inputPath, file_name)\n",
    "            output_path = os.path.join(outputPath, \n",
    "                                       file_name.replace(oldExtension,\n",
    "                                                         newExtension))\n",
    "\n",
    "            # load the image\n",
    "            # https://stackoverflow.com/questions/40751523/how-do-you-read-a-32-bit-tiff-image-in-python\n",
    "            img = cv2.imread(input_path,-1)\n",
    "            \n",
    "            # convert to RGB format if necessary\n",
    "            if img.shape[2] == 1:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            elif img.shape[2] == 4:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
    "\n",
    "            # Save the image as a .jpg file\n",
    "            cv2.imwrite(output_path, img, [int(cv2.IMWRITE_JPEG_QUALITY), 90])\n",
    "            \n",
    "            if verbose==True:\n",
    "                print(f\"Conversion complete: {input_path} -> {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aeda35df-a209-4e92-b02b-9e49b40d02d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test function\n",
    "\n",
    "inp='/Users/sra/temp/'\n",
    "out='/Users/sra/temp2'\n",
    "\n",
    "imageConverter(inputPath=inp,outputPath=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9db9f5fe-3388-444b-bbd5-f642793fd4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup lists for jpg converter function\n",
    "\n",
    "source_city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_city'\n",
    "source_farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire_farm'\n",
    "source_fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire1'\n",
    "source_fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire_fire2'\n",
    "\n",
    "sources=[source_city,\n",
    "        source_farm,\n",
    "        source_fire1,\n",
    "        source_fire2]\n",
    "\n",
    "dest_city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/city'\n",
    "dest_farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/farm'\n",
    "dest_fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire1'\n",
    "dest_fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2'\n",
    "\n",
    "dests=[dest_city,\n",
    "      dest_farm,\n",
    "      dest_fire1,\n",
    "      dest_fire2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "96256678-41a4-4fe7-95b7-3ec5cf75f3e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2'\n",
    "\n",
    "if filePresenceSumChecker(directory=source,extension='.jpg')==0:\n",
    "    for src,des in zip(sources,dests):\n",
    "        imageConverter(inputPath=src,outputPath=des)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a527f-8944-47d8-bd09-5af588de9e06",
   "metadata": {},
   "source": [
    "Now we can move the nonsquare `.jpg` images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c41f04eb-73df-431b-aec2-616b3028ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveNonSquareJPG(source_folder:str, destination_folder:str):\n",
    "    '''\n",
    "    Checks to see if any JPG or PNG in the source folder\n",
    "    does not have square dimensions (e.g. 29x128 is not square,\n",
    "    128x128 is).\n",
    "    \n",
    "    If they do, they are sent to the destination_folder.\n",
    "    \n",
    "    ----\n",
    "    Inputs\n",
    "    \n",
    "    >source_folder\n",
    "    the source of the images to be checked\n",
    "    \n",
    "    >destination_folder\n",
    "    where the non-square images will be relocated to\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Create destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    \n",
    "    # get a list of all image files in the source folder\n",
    "    image_files = [f for f in os.listdir(source_folder) if \\\n",
    "                   f.endswith('.jpg') or \\\n",
    "                   f.endswith('.jpeg') or \\\n",
    "                   f.endswith('.png')]\n",
    "    \n",
    "    for file_name in image_files:\n",
    "        # open the image using PIL\n",
    "        img = Image.open(os.path.join(source_folder, file_name))\n",
    "        \n",
    "        # check if image is square\n",
    "        if img.size[0] != img.size[1]:\n",
    "            # move the image to the destination folder\n",
    "            shutil.move(os.path.join(source_folder, file_name), os.path.join(destination_folder, file_name))\n",
    "            # # delete the non-square image from the source folder\n",
    "            # os.remove(os.path.join(source_folder, file_name))\n",
    "        \n",
    "    # friendly notice\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aa4082b9-1389-4618-9992-90ade8ad2192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# test function\n",
    "source_='/Users/sra/temp2'\n",
    "dest_='/Users/sra/temp'\n",
    "\n",
    "moveNonSquareJPG(source_folder=source_,destination_folder=dest_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b462e2ee-d441-4210-9f3d-28a841f6d07e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup lists for function\n",
    "\n",
    "source_city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/city'\n",
    "source_farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/farm'\n",
    "source_fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire1'\n",
    "source_fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/_patch_jpg/fire2'\n",
    "\n",
    "sources=[source_city,\n",
    "        source_farm,\n",
    "        source_fire1,\n",
    "        source_fire2]\n",
    "\n",
    "dest_city='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/jpg/city'\n",
    "dest_farm='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/jpg/farm'\n",
    "dest_fire1='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/jpg/fire1'\n",
    "dest_fire2='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/jpg/fire2'\n",
    "\n",
    "dests=[dest_city,\n",
    "      dest_farm,\n",
    "      dest_fire1,\n",
    "      dest_fire2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7aca16e3-2a27-4d21-a24e-3fa43f16d5bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Done!\n",
      "Done!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# setup flow control\n",
    "\n",
    "directory_='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/jpg/city'\n",
    "\n",
    "if filePresenceSumChecker(directory=directory_,extension='.jpg') == 0:\n",
    "    for src,dest in zip(sources,dests):\n",
    "        moveNonSquareJPG(source_folder=src,\n",
    "                         destination_folder=dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649eeca3-9cce-4dc6-957a-e8d1db45cdc4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641c6c2-4d2a-4827-8d57-8feebc4f2880",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8115af3-ae1d-4857-8360-e3be394e71c1",
   "metadata": {},
   "source": [
    "To do this, we will create function to generate lists of unique numbers that will serve as the random selector for setting up train/test/validation splits:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac339be-5505-439b-9353-668d77fd1a59",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b09ebe02-ad30-424b-80ff-350edc906abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createTVTS(start,total_img:int,step=1,\n",
    "              valid_frac=0.15,test_frac=0.15,\n",
    "              replace=False,verbose=True,debug=False):\n",
    "    '''\n",
    "    Creates three lists for a train/validation/test split of \n",
    "    numbered files, such as patches previously made from \n",
    "    a larger image to be used in convolutional neural network \n",
    "    workflows.\n",
    "    \n",
    "    The training fraction of the output is the remainder of\n",
    "    the sum of the validation fraction and the testing fraction:\n",
    "    \n",
    "    train_frac = 1 - (valid_frac + test_frac)\n",
    "    \n",
    "    Default splits are:\n",
    "        0.7    = 1 - (   .15     +    .15 )\n",
    "    \n",
    "    Please ensure that you have a reasonable split amongst these\n",
    "    three groups.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >start\n",
    "    starting number for the image patches\n",
    "    \n",
    "    >total_img\n",
    "    serves both as total size of images in the patch set\n",
    "    \n",
    "    >step\n",
    "    defaults to 1, the step size in creating a list of numbers\n",
    "    \n",
    "    >valid_frac\n",
    "    the fraction of the numbers that will be split into the\n",
    "    validation set. Please make the number between 0 and 1\n",
    "    \n",
    "    >train_frac\n",
    "    the fraction of the numbers that will be split into the\n",
    "    training set. Please make the number between 0 and 1\n",
    "    \n",
    "    >replace\n",
    "    since this function is splitting the numbers, replace defaults\n",
    "    to False\n",
    "    \n",
    "    >verbose\n",
    "    runs a line of code to check that the splitting was successful\n",
    "    \n",
    "    >debug\n",
    "    helpful print statements to show you what step function is on.\n",
    "    defaults to not showing these statements\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >train_valid_test_tuple\n",
    "    a tuple of three lists, containing the train, valid, and\n",
    "    test list that when combined together are the same size as\n",
    "    the total_img value\n",
    "    \n",
    "    '''\n",
    "#     create list with each image's number\n",
    "#     there are `total_img` images each in the fire and nofire datasets\n",
    "    file_nums=np.arange(start,total_img,step)\n",
    "    if debug==True:\n",
    "        print(f'created initial list of size {total_img}')\n",
    "        \n",
    "#     create train fraction\n",
    "    train_frac=1-(valid_frac+test_frac)\n",
    "    if debug==True:\n",
    "        print(f'created train_fraction ({train_frac})')\n",
    "    \n",
    "#     create train, valid, and test splits    \n",
    "    trains = np.random.choice(file_nums,\n",
    "                              size=int(total_img * train_frac),\n",
    "                              replace=False)\n",
    "    if debug==True:\n",
    "        print('created train list')\n",
    "    \n",
    "    valids = np.random.choice(np.setdiff1d(file_nums, trains),\n",
    "                              size=int(total_img * valid_frac),\n",
    "                              replace=False)\n",
    "    if debug==True:\n",
    "        print('created validation list')\n",
    "    \n",
    "    tests = np.random.choice(np.setdiff1d(file_nums, np.concatenate((trains, valids))),\n",
    "                             size=int(total_img * test_frac),\n",
    "                             replace=False)\n",
    "    if debug==True:\n",
    "        print('created test list')\n",
    "    \n",
    "    # tests=list(set(file_nums)-set(trains))\n",
    "\n",
    "    if verbose==True:\n",
    "        print(f'The size of train ({len(trains)}), validation ({len(valids)}), and tests ({len(tests)}) together is {len(trains)+len(valids)+len(tests)}')\n",
    "        if debug==True:\n",
    "            print('printed size of train, validation, and test')\n",
    "            \n",
    "    train_valid_test_tuple=(trains,tests,valids)\n",
    "    if debug==True:\n",
    "         print('created tuple of train, validation, and test')\n",
    "    \n",
    "    return train_valid_test_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c02256-af43-4515-8c1f-caba766ac6a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b9f349be-f706-4d76-86bf-de50e5058a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created initial list of size 7760\n",
      "created train_fraction (0.7)\n",
      "created train list\n",
      "created validation list\n",
      "created test list\n",
      "The size of train (5432), validation (1164), and tests (1164) together is 7760\n",
      "printed size of train, validation, and test\n",
      "created tuple of train, validation, and test\n",
      "5432\n",
      "1164\n",
      "1164\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# run function\n",
    "train_valid_test_tuple=createTVTS(start=0,total_img=7760,\\\n",
    "                                  step=1,verbose=True,\\\n",
    "                                  debug=True)\n",
    "# train_valid_test_tuple\n",
    "\n",
    "# sanity checks\n",
    "trains=train_valid_test_tuple[0]\n",
    "valids=train_valid_test_tuple[1]\n",
    "tests=train_valid_test_tuple[2]\n",
    "\n",
    "print(len(trains))\n",
    "print(len(valids))\n",
    "print(len(tests))\n",
    "\n",
    "print(set(trains) & set(valids) & set(tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2a97ec11-634e-417b-803f-f274c305ee88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1179, 5283, 7319, ..., 4356, 5760, 3943])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b9963231-e06f-4fc4-816d-7aae699b8a37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert list of integers to list of strings\n",
    "# important for moving files in next step\n",
    "trains=[str(i) for i in trains]\n",
    "valids=[str(i) for i in valids]\n",
    "tests=[str(i) for i in tests]\n",
    "\n",
    "type(trains[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc319d-0018-4d16-b394-a68c37385302",
   "metadata": {},
   "source": [
    "### Move the images to their corresponding training and validation locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "164bc6ce-8590-4a00-bb58-152f7d6db5c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def copyFileByNumber(source, dest, set_):\n",
    "    '''\n",
    "    Copies files from `source` to `dest` that have numbers \n",
    "    in their filename and that match any element in `set_` \n",
    "    list (either trains, valids, or tests).\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >source\n",
    "    source of files to be copied\n",
    "    \n",
    "    >dest\n",
    "    destination of files to be moved to\n",
    "    \n",
    "    >set_\n",
    "    specify either the training ('trains'), validation\n",
    "    ('valids') or test ('tests') set\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    copies files, no further output\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for filename in os.listdir(source):\n",
    "        # Get the number in the filename\n",
    "        file_num = \"\".join(filter(str.isdigit, filename))\n",
    "        # Check if the number is in the trains list\n",
    "        if file_num in set_:\n",
    "            # Copy the file to the destination folder\n",
    "            shutil.copy(os.path.join(source, filename), dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ecbe557-9208-4669-afa4-6f1c99229a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6187c0e8-feb9-44a1-aaa5-840d6f13b890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup loop for copyFileByNumber\n",
    "\n",
    "source_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire'\n",
    "source_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire'\n",
    "source_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire'\n",
    "source_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire'\n",
    "source_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_fire'\n",
    "source_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/patch_nofire'\n",
    "\n",
    "\n",
    "dest_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "dest_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "dest_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "dest_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "dest_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "dest_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "\n",
    "sources = [source_train_fire,\n",
    "          source_train_nofire,\n",
    "          source_valid_fire,\n",
    "          source_valid_nofire,\n",
    "          source_test_fire,\n",
    "          source_test_nofire]\n",
    "\n",
    "dests = [dest_train_fire,\n",
    "        dest_train_nofire,\n",
    "        dest_valid_fire,\n",
    "        dest_valid_nofire,\n",
    "        dest_test_fire,\n",
    "        dest_test_nofire]\n",
    "\n",
    "sets = [trains,\n",
    "        trains,\n",
    "        valids,\n",
    "        valids,\n",
    "        tests,\n",
    "        tests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7a686691-4feb-4a75-ac73-2a6e8364d24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run function to move subsets of patches\n",
    "# flow control\n",
    "if filePresenceSumChecker(directory=dests[0],extension='.tif')==0:\n",
    "    for src,des,sts in zip(sources,dests,sets):\n",
    "        copyFileByNumber(source=src,dest=des,set_=sts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea6bcb8-7877-493e-acf8-c23afa3fc165",
   "metadata": {},
   "source": [
    "### Rename files and change to proper format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbb71fd-617d-4845-a231-087d7fb691ba",
   "metadata": {},
   "source": [
    "Convert filenames from `patch_fire.X.tif` to `patch_fire_X.tif`, where X is a number with one or more digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "224caa0d-be99-4865-a6f9-580d9e61eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileRenamer(source:str, prefix:str,extension='.tif'):\n",
    "    '''\n",
    "    Renames files to the format provided by the user.\n",
    "    It can help clean an image format to one that can be\n",
    "    read by modules like Tensorflow.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >source\n",
    "    the directory where the files are located\n",
    "    \n",
    "    >prefix\n",
    "    the base part of the filename that will remain\n",
    "    \n",
    "    >extension\n",
    "    defaults to '.tif', but this will ensure you only rename\n",
    "    certain files that have the specified extension\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    renames files in-place, no further output\n",
    "    '''\n",
    "\n",
    "    # loop over each file from the source directory\n",
    "    for filename in os.listdir(source):\n",
    "        \n",
    "        # check if the file is the provided `ext` (extension)\n",
    "        if filename.endswith(extension):\n",
    "            \n",
    "            # split the filename into base and extension\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            \n",
    "            # split the base into the prefix and number parts\n",
    "            prefix, number = base.split('.', 1)\n",
    "            \n",
    "            # create the new filename with the desired format\n",
    "            new_filename = f'{prefix}_{number}{ext}'\n",
    "            \n",
    "            # rename the file\n",
    "            os.rename(os.path.join(source, filename), \n",
    "                      os.path.join(source, new_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f56bedc5-7295-4939-8e8b-67fb8ccd846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a for loop to rename all the files\n",
    "\n",
    "source_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "source_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "source_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "source_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "source_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "source_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "\n",
    "sources=[source_train_fire,\n",
    "        source_train_nofire,\n",
    "        source_valid_fire,\n",
    "        source_valid_nofire,\n",
    "        source_test_fire,\n",
    "        source_test_nofire]\n",
    " \n",
    "# flow control\n",
    "if filePresenceSumChecker(directory=source_train_fire,extension='.tif')<0:\n",
    "    for src in sources:    \n",
    "        fileRenamer(source=src,prefix='patch_fire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "06bf3ab4-7a7b-4f54-84b4-9a532bd4ad86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = '/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "extension = '.jpg'\n",
    "\n",
    "filePresenceSumChecker(directory=directory,extension=extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "41262501-a201-41d7-b6d7-39efe1e43932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for loop\n",
    "\n",
    "inputPath_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "inputPath_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "inputPath_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "inputPath_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "inputPath_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "inputPath_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "\n",
    "outputPath_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "outputPath_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "outputPath_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "outputPath_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "outputPath_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "outputPath_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "\n",
    "inputPaths=[inputPath_train_fire,\n",
    "            inputPath_train_nofire,\n",
    "            inputPath_valid_fire,\n",
    "            inputPath_valid_nofire,\n",
    "            inputPath_test_fire,\n",
    "            inputPath_test_nofire]\n",
    "\n",
    "outputPaths=[outputPath_train_fire,\n",
    "            outputPath_train_nofire,\n",
    "            outputPath_valid_fire,\n",
    "            outputPath_valid_nofire,\n",
    "            outputPath_test_fire,\n",
    "            outputPath_test_nofire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ea6eb6eb-2d80-4a89-becd-1d5c3daecdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow control\n",
    "if filePresenceSumChecker(directory=outputPath_train_fire,extension='.jpg')==0:\n",
    "    for inp,outp in zip(inputPaths,outputPaths):\n",
    "        imageConverter(inputPath=inp,outputPath=outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "93800cdf-66c9-40a2-894e-f059c7257d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1164"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePresenceSumChecker(directory='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire',\n",
    "                      extension='.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f68c16a-1068-46ed-8e05-807a6be6d4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fileDeleter(source:str, extension:str='.tif'):\n",
    "    '''\n",
    "    Deletes files with the provided extension from the source directory.\n",
    "    \n",
    "    ----\n",
    "    Inputs:\n",
    "    \n",
    "    >source\n",
    "    the directory where the files are located\n",
    "    \n",
    "    >extension\n",
    "    defaults to '.tif', but this will ensure you only delete\n",
    "    certain files that have the specified extension\n",
    "    \n",
    "    ----\n",
    "    Outputs:\n",
    "    \n",
    "    >N/A\n",
    "    deletes files in-place, no further output\n",
    "    '''\n",
    "    \n",
    "    # loop over each file from the source directory\n",
    "    for filename in os.listdir(source):\n",
    "        \n",
    "        # check if the file is the provided `ext` (extension)\n",
    "        if filename.endswith(extension):\n",
    "            \n",
    "            # delete the file\n",
    "            os.remove(os.path.join(source, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2f03e2e2-0644-4d96-927f-8e0fe667f089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup for loop\n",
    "\n",
    "inputPath_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "inputPath_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "inputPath_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "inputPath_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "inputPath_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "inputPath_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "inputPaths=[inputPath_train_fire,\n",
    "            inputPath_train_nofire,\n",
    "            inputPath_valid_fire,\n",
    "            inputPath_valid_nofire,\n",
    "            inputPath_test_fire,\n",
    "            inputPath_test_nofire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cdb963db-be52-4ba4-a1d3-0f338b1e63e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# flow control\n",
    "if filePresenceSumChecker(directory=inputPath_train_fire,extension='.tif')>0:\n",
    "    for inp in (inputPaths):\n",
    "        fileDeleter(source=inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2285dd83-7db9-4119-9f80-e358f3fb1441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/validation/nofire'\n",
    "\n",
    "input_path='/Users/sra/temp'\n",
    "output_path='/Users/sra/temp3'\n",
    "\n",
    "if filePresenceSumChecker(directory=output_path,extension='.jpg') != 0:\n",
    "    separateNonSquareImages(input_path=input_path,output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c392543-8dce-466a-bec3-557262105ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for loop\n",
    "\n",
    "inputPath_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/fire'\n",
    "inputPath_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/train/nofire'\n",
    "inputPath_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/fire'\n",
    "inputPath_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/validation/nofire'\n",
    "inputPath_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/fire'\n",
    "inputPath_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/test/nofire'\n",
    "\n",
    "destPath_train_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/train/fire'\n",
    "destPath_train_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/train/nofire'\n",
    "destPath_valid_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/validation/fire'\n",
    "destPath_valid_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/validation/nofire'\n",
    "destPath_test_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/test/fire'\n",
    "destPath_test_nofire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/test/nofire'\n",
    "\n",
    "inputPaths=[inputPath_train_fire,\n",
    "            inputPath_train_nofire,\n",
    "            inputPath_valid_fire,\n",
    "            inputPath_valid_nofire,\n",
    "            inputPath_test_fire,\n",
    "            inputPath_test_nofire]\n",
    "\n",
    "destPaths=[destPath_train_fire,\n",
    "          destPath_train_nofire,\n",
    "          destPath_valid_fire,\n",
    "          destPath_valid_nofire,\n",
    "          destPath_test_fire,\n",
    "          destPath_test_nofire]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0fe7ef10-b436-4fad-9b15-5449901b38be",
   "metadata": {},
   "outputs": [],
   "source": [
    "checked_location='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/nonsquares/validation/nofire'\n",
    "\n",
    "if filePresenceSumChecker(directory=checked_location,extension='.jpg') == 0:\n",
    "    for inp,des in zip(inputPaths,destPaths):\n",
    "        moveNonSquareImages(source_folder=inp,destination_folder=des)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ab51f-13d0-4c24-8761-dd7bc85ec925",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Clip raster to polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798acac-b2e2-40a2-a76e-217059b245b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr\n",
    "\n",
    "# Define the input raster and polygon mask\n",
    "input_raster = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722.tif\"\n",
    "mask = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/perimeters_sm/santa_monica_fire_perimeters_fire_valid.shp\"\n",
    "\n",
    "# Open the input raster and polygon mask\n",
    "raster_ds = gdal.Open(input_raster)\n",
    "mask_ds = ogr.Open(mask)\n",
    "\n",
    "# Get the mask layer\n",
    "mask_lyr = mask_ds.GetLayer()\n",
    "\n",
    "# Get the extent of the mask layer\n",
    "mask_extent = mask_lyr.GetExtent()\n",
    "\n",
    "# Set the output file name and format\n",
    "output_file = \"path/to/clipped_raster.tif\"\n",
    "output_format = \"GTiff\"\n",
    "\n",
    "# Set the output file resolution\n",
    "output_res = raster_ds.GetGeoTransform()[1]\n",
    "\n",
    "# Define the output file size\n",
    "output_width = int((mask_extent[1] - mask_extent[0]) / output_res)\n",
    "output_height = int((mask_extent[3] - mask_extent[2]) / output_res)\n",
    "\n",
    "# Define the warp options\n",
    "warp_options = gdal.WarpOptions(cutlineDSName=mask, cropToCutline=True, dstSRS=raster_ds.GetProjection(), outputBounds=mask_extent, xRes=output_res, yRes=output_res, width=output_width, height=output_height)\n",
    "\n",
    "# Call the gdal.Warp() function to clip the raster\n",
    "clipped_raster_ds = gdal.Warp(output_file, raster_ds, options=warp_options)\n",
    "\n",
    "# Save clipped raster to a shapefile\n",
    "output_shp = \"path/to/clipped_raster.shp\"\n",
    "gdal.VectorTranslate(output_shp, clipped_raster_ds, format=\"ESRI Shapefile\")\n",
    "\n",
    "# Save clipped raster to a GeoJSON\n",
    "output_geojson = \"path/to/clipped_raster.geojson\"\n",
    "gdal.VectorTranslate(output_geojson, clipped_raster_ds, format=\"GeoJSON\")\n",
    "\n",
    "# Clean up\n",
    "raster_ds = None\n",
    "mask_ds = None\n",
    "clipped_raster_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23256ed2-3407-4ff5-a0c0-5702da487a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr\n",
    "\n",
    "# Define the input raster and polygon mask\n",
    "input_raster = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722.tif\"\n",
    "mask = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/perimeters_sm/santa_monica_fire_perimeters_fire_valid.shp\"\n",
    "\n",
    "# Open the input raster and polygon mask\n",
    "raster_ds = gdal.Open(input_raster)\n",
    "mask_ds = ogr.Open(mask)\n",
    "\n",
    "# Get the mask layer\n",
    "mask_lyr = mask_ds.GetLayer()\n",
    "\n",
    "# Get the extent of the mask layer\n",
    "mask_extent = mask_lyr.GetExtent()\n",
    "\n",
    "# Set the output file name and format for GeoTIFF\n",
    "output_file_tif = \"path/to/clipped_raster.tif\"\n",
    "output_format_tif = \"GTiff\"\n",
    "\n",
    "# Set the output file name and format for GeoJSON\n",
    "output_file_geojson = \"path/to/clipped_raster.geojson\"\n",
    "output_format_geojson = \"GeoJSON\"\n",
    "\n",
    "# Set the output file resolution\n",
    "output_res = raster_ds.GetGeoTransform()[1]\n",
    "\n",
    "# Define the output file size\n",
    "output_width = int((mask_extent[1] - mask_extent[0]) / output_res)\n",
    "output_height = int((mask_extent[3] - mask_extent[2]) / output_res)\n",
    "\n",
    "# Define the warp options\n",
    "warp_options = gdal.WarpOptions(cutlineDSName=mask, cropToCutline=True, dstSRS=raster_ds.GetProjection(), outputBounds=mask_extent, xRes=output_res, yRes=output_res, width=output_width, height=output_height)\n",
    "\n",
    "# Call the gdal.Warp() function to clip the raster\n",
    "clipped_raster_ds = gdal.Warp('', raster_ds, options=warp_options)\n",
    "\n",
    "# Save clipped raster to GeoTIFF\n",
    "output_tif = \"path/to/clipped_raster.tif\"\n",
    "gdal.Translate(output_tif, clipped_raster_ds, format=output_format_tif)\n",
    "\n",
    "# Save clipped raster to GeoJSON\n",
    "output_geojson = \"path/to/clipped_raster.geojson\"\n",
    "gdal.Translate(output_file_geojson, clipped_raster_ds, format=output_format_geojson)\n",
    "\n",
    "# Save clipped raster to a shapefile\n",
    "output_shp = \"path/to/clipped_raster.shp\"\n",
    "gdal.VectorTranslate(output_shp, clipped_raster_ds, format=\"ESRI Shapefile\")\n",
    "\n",
    "# Clean up\n",
    "raster_ds = None\n",
    "mask_ds = None\n",
    "clipped_raster_ds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af8e27-b327-42c9-b65e-c86d10408814",
   "metadata": {},
   "source": [
    "## [Extrating Patches from Large Images ~~and Masks~~ for Semantic Segmentation](https://www.youtube.com/watch?v=7IL7LKSLb9I)\n",
    "\n",
    "Following this tutorial to convert my large fire/nofire images into patches for neural network analysis. The code block below is from this video, with some alterations to adapt it to my use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d314417-7d91-45a0-93de-d30e6264187c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from patchify import patchify\n",
    "import tifffile as tiff\n",
    "\n",
    "# large_image_stack_fire=tiff.imread('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_sm_fire.tif')\n",
    "\n",
    "large_image_stack_patch_fire=tiff.imread('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/img_patch_fire2.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f55fc2-3190-47e8-a311-2403ca83bed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@347.904] global /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/grfmt_tiff.cpp (629) readData OpenCV TIFF: TIFFRGBAImageOK: Sorry, can not handle images with 32-bit samples\n"
     ]
    }
   ],
   "source": [
    "# updated \n",
    "# https://stackoverflow.com/questions/68224588/problem-when-using-patchify-library-to-create-patches\n",
    "\n",
    "import cv2\n",
    "\n",
    "# filepaths\n",
    "target_tiff_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches/img_patch_fire2.tif'\n",
    "output_location_fire='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/patches'\n",
    "\n",
    "# read large_image_stack_test\n",
    "img = cv2.imread(target_tiff_fire)\n",
    "\n",
    "# cv2.imshow('image',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed44680e-d00b-41fc-91f3-e53c9ce668ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/loadsave.cpp:77: error: (-215:Assertion failed) pixels <= CV_IO_MAX_IMAGE_PIXELS in function 'validateInputImageSize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m output_location_fire\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/m_3411849_se_11_060_20180722/patches_fire\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# read large_image_stack_test\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_tiff_fire\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m patches_img \u001b[38;5;241m=\u001b[39m patchify(img, (\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m3\u001b[39m), step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(patches_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /private/var/folders/nz/j6p8yfhx1mv_0grj5xl4650h0000gp/T/abs_d9lyif19nl/croot/opencv-suite_1676472756314/work/modules/imgcodecs/src/loadsave.cpp:77: error: (-215:Assertion failed) pixels <= CV_IO_MAX_IMAGE_PIXELS in function 'validateInputImageSize'\n"
     ]
    }
   ],
   "source": [
    "patches_img = patchify(img, (128,128,3), step=128)\n",
    "\n",
    "for i in range(patches_img.shape[0]):\n",
    "    for j in range(patches_img.shape[1]):\n",
    "        single_patch_img = patches_img[i, j, 0, :, :, :]\n",
    "        if not cv2.imwrite(output_location_fire + 'image_' + '_'+ str(i)+str(j)+'.jpg', single_patch_img):\n",
    "            raise Exception(\"Could not write the image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6489ba4e-9b52-4484-82af-5f76bd372c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ce976-06da-4f90-b9cc-121df77a06b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6092d7-67cc-4d76-8dd0-aea688fa6eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
