{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afe2082",
   "metadata": {},
   "source": [
    "# Welcome  \n",
    "\n",
    "Notebook Author: Samuel Alter  \n",
    "Notebook Subject: Capstone Project - Satellite Imagery\n",
    "\n",
    "BrainStation Winter 2023: Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c7439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd40325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from usgs import api\n",
    "\n",
    "# Set the EarthExplorer catalog\n",
    "node = 'EE'# this indicates earth explorer website\n",
    "\n",
    "# Set the Hyperion and Landsat 8 dataset\n",
    "hyperion_dataset = 'EO1_HYP_PUB'\n",
    "landsat8_dataset = 'LANDSAT_8'\n",
    "\n",
    "# Set the scene ids\n",
    "hyperion_scene_id = 'EO1H1820422014302110K2_SG1_01'\n",
    "landsat8_scene_id = 'LC80290462015135LGN00'\n",
    "\n",
    "# Submit requests to USGS servers\n",
    "api.metadata(hyperion_dataset, node, [hyperion_scene_id])\n",
    "api.metadata(landsat8_dataset, node, [landsat8_scene_id])\n",
    "\n",
    "usgs.api.metadata(dataset, node, entityids, extended=False, api_key=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/satellite-imagery-access-and-analysis-in-python-jupyter-notebooks-387971ece84b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelsat import SentinelAPI\n",
    "\n",
    "user = 'sralter' \n",
    "password = 'rcy1qmr-btk1DFT1eba' \n",
    "api = SentinelAPI(user, password, 'https://scihub.copernicus.eu/dhus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium \n",
    "\n",
    "# santa monica bounds file named nReserve\n",
    "nReserve = gpd.read_file('/Users/sra/Files/brainstation_2023_ds_capstone/brainstation_2023_ds_capstone/01_capstone_data/shapefiles/santa_monica_bounds/sm_bounds.geojson')\n",
    "\n",
    "# empty base map in Folium centered around the bounding box\n",
    "m = folium.Map([34.08483,-118.70617], zoom_start=12)\n",
    "folium.GeoJson(nReserve).add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28538908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "footprint = None\n",
    "for i in nReserve['geometry']:\n",
    "    footprint = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5963d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = api.query(footprint,\n",
    "                     #date = ('20190601', '20190626'),\n",
    "                     date = ('20220101', '20221231'),\n",
    "                     platformname = 'Sentinel-2',\n",
    "                     processinglevel = 'Level-2A',\n",
    "                     cloudcoverpercentage = (0,15)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811fecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_gdf = api.to_geodataframe(products)\n",
    "products_gdf_sorted = products_gdf.sort_values(['cloudcoverpercentage'], ascending=[True])\n",
    "products_gdf_sorted\n",
    "products_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c557586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api.download('becdf74b-fb47-4010-84f1-2c271a501266')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2308fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "R10 = '/Users/sra/Files/brainstation_2023_ds_capstone/brainstation_2023_ds_capstone/01_capstone_data/notebooks/S2A_MSIL2A_20221224T183801_N0509_R027_T11SLT_20221224T213852.SAFE/GRANULE/L2A_T11SLT_A039206_20221224T184116/IMG_DATA/R10m'\n",
    "b4 = rio.open(R10+'/T11SLT_20221224T183801_B04_10m.jp2')\n",
    "b3 = rio.open(R10+'/T11SLT_20221224T183801_B03_10m.jp2')\n",
    "b2 = rio.open(R10+'/T11SLT_20221224T183801_B02_10m.jp2')\n",
    "\n",
    "\n",
    "# Create an RGB image \n",
    "with rio.open('RGB.tiff','w',driver='Gtiff', width=b4.width, height=b4.height, \n",
    "              count=3,crs=b4.crs,transform=b4.transform, dtype=b4.dtypes[0]) as rgb:\n",
    "    rgb.write(b2.read(1),1) \n",
    "    rgb.write(b3.read(1),2) \n",
    "    rgb.write(b4.read(1),3) \n",
    "    rgb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ab51f-13d0-4c24-8761-dd7bc85ec925",
   "metadata": {},
   "source": [
    "# Clip raster to polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758da3cc-7217-4d06-bedf-32e6088b6a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97498d-892b-4ad2-bd97-ccb595c758fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapely.geos.geos_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3c0aa-ae14-410a-83ae-9776f43e1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, merge perimeters\n",
    "# https://stackoverflow.com/questions/61035170/merging-polygon-shapefiles-in-python\n",
    "\n",
    "# this was done in QGIS for now. View merged perimeters, \n",
    "# to confirm only one polygon in the dataset\n",
    "sm_perim_merge=gpd.read_file('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/perimeters_sm/santa_monica_fire_perimeters_le2018_merge.geojson')\n",
    "sm_perim_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f141a3-63bf-4576-9f95-cc0d41e39b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates from geometry of sm_perim_merge\n",
    "\n",
    "sm_perim_merge['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9954acc5-d702-4c12-a075-40d1a5bdc7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "\n",
    "gdal.UseExceptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3df62-50ad-4bbd-a9af-a8d55693dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define filenames\n",
    "\n",
    "# raster in\n",
    "rasin='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_merge_clip.tif'\n",
    "# CRS:\n",
    "# Coordinate Reference System (CRS)\n",
    "# Name\t\t\t\tEPSG:26911 - NAD83 / UTM zone 11N\n",
    "# Units\t\t\t\tmeters\n",
    "# Method\t\t\tUniversal Transverse Mercator (UTM)\n",
    "# Celestial body\tEarth\n",
    "# Reference\t\t\tStatic (relies on a datum which is plate-fixed)\n",
    "\n",
    "\n",
    "# shapefile in\n",
    "shpin='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/perimeters_sm/santa_monica_fire_perimeters_le2018_merge_shp.shp'\n",
    "# I reprojected the shapefile to the same crs as the raster above in QGIS\n",
    "# Coordinate Reference System (CRS)\n",
    "\n",
    "# Name\n",
    "# EPSG:26911 - NAD83 / UTM zone 11N\n",
    "# Units\n",
    "# meters\n",
    "# Method\n",
    "# Universal Transverse Mercator (UTM)\n",
    "# Celestial body\n",
    "# Earth\n",
    "# Reference\n",
    "# Static (relies on a datum which is plate-fixed)\n",
    "\n",
    "\n",
    "# raster out\n",
    "rasout='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_sm_fire.tif'\n",
    "\n",
    "#                 out     in\n",
    "result=gdal.Warp(rasout,rasin,cutlineDSName=shpin)\n",
    "\n",
    "iface.addRasterLayer(rasout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ab991-9f47-4d3a-85e8-0630041c68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://opensourceoptions.com/blog/how-to-clip-a-raster-to-a-polygon-or-an-extent-with-python-extract-by-mask/\n",
    "\n",
    "import gdal\n",
    "\n",
    "fn_in = r\"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_merge_clip.tif\"\n",
    "fn_clip = '/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_merge_sm_fire.tif'\n",
    "fn_poly = r\"path/to/polygon.gpkg\"\n",
    "\n",
    "# gdal.Warp(fn_clip, fn_in, cutlineDSName=fn_poly, cutlineLayer='polygon', cropToCutline=True)\n",
    "\n",
    "# from osgeo import gdal\n",
    "# fn_in = r\"..\\..\\course-gdal-python\\data\\input\\USGS_one_meter_x64y486_ID_FEMAHQ_2018.tif\"\n",
    "fn_in=r'/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_merge_clip.tif'\n",
    "\n",
    "# fn_poly = r\"..\\..\\course-gdal-python\\data\\input\\polygon.gpkg\"\n",
    "fn_poly=r'/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/perimeters_sm/santa_monica_fire_perimeters_le2018_merge.geojson'\n",
    "\n",
    "# fn_clip = '../data/output/clip_polygon.tif'\n",
    "fn_clip='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_merge_clip_fire.tif'\n",
    "\n",
    "\n",
    "ortho_fire=gdal.Warp(fn_clip, fn_in, cutlineDSName=fn_poly, cutlineLayer='polygon', cropToCutline=True)\n",
    "ortho_fire\n",
    "# gdal.Warp(fn_clip2, fn_in, cutlineDSName=fn_poly, cutlineLayer='polygon', cropToCutline=False)\n",
    "# where = \"ID = '1'\"\n",
    "# gdal.Warp(fn_clip_where1, fn_in, cutlineDSName=fn_poly, cutlineLayer='polygon', cropToCutline=True, cutlineWhere=where)\n",
    "# where = \"ID = '2'\"\n",
    "# gdal.Warp(fn_clip_where2, fn_in, cutlineDSName=fn_poly, cutlineLayer='polygon', cropToCutline=True, cutlineWhere=where)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee242ee5-4e11-4f95-bdf7-d171ddae0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://automating-gis-processes.github.io/CSC18/lessons/L6/clipping-raster.html\n",
    "\n",
    "# imports\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.plot import show_hist\n",
    "from rasterio.mask import mask\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "from fiona.crs import from_epsg\n",
    "import pycrs\n",
    "\n",
    "# filepaths\n",
    "fp=r'/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_merge_clip.tif'\n",
    "out_tif=r'/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_merge_clip_fire.tif'\n",
    "\n",
    "# plot raster\n",
    "data=rasterio.open(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2bf157-c213-491d-8046-9fe9c93224cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show((data,4),cmap='terrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7a55c-b998-44c4-8903-c675dcf8527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9b6515-ca04-4401-a635-96e1214d59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to insert geometry into a geodataframe\n",
    "\n",
    "polygon='/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/perimeters_sm/santa_monica_fire_perimeters_le2018_merge.geojson'\n",
    "\n",
    "geo=gpd.GeoDataFrame({'geometry':polygon},index=[0],crs=from_epsg(4326))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3042d2-53c9-453e-8fe4-5de6ab239802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to re-project into the same coordinate system as the raster data\n",
    "\n",
    "geo = geo.to_crs(crs=data.crs.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8536ff8e-8933-4e1f-9abf-0936e5c62406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coordinates of the geometry in a format that rasterio wants them\n",
    "def getFeatures(gdf):\n",
    "    \"\"\"Function to parse features from GeoDataFrame in such a manner that rasterio wants them\"\"\"\n",
    "    import json\n",
    "    return [json.loads(gdf.to_json())['features'][0]['geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec9535-d064-429a-92f0-d8b303dd61fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = getFeatures(geo)\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2363820-dfa1-4856-ae2c-a02ecc966d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready to clip the raster with the polygon \n",
    "# using the coords variable that we just created. \n",
    "# Clipping the raster can be done easily with the mask function \n",
    "# that we imported in the beginning from rasterio, and specifying clip=True.\n",
    "\n",
    "out_img, out_transform = mask(raster=data, shapes=coords, crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af8e27-b327-42c9-b65e-c86d10408814",
   "metadata": {},
   "source": [
    "## [Extrating Patches from Large Images and Masks for Semantic Segmentation](https://www.youtube.com/watch?v=7IL7LKSLb9I)\n",
    "\n",
    "Following this tutorial to convert my large fire/nofire images into patches for neural network analysis. The code block below is from this video, with some alterations to adapt it to my use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d314417-7d91-45a0-93de-d30e6264187c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from patchify import patchify\n",
    "import tifffile as tiff\n",
    "\n",
    "# large_image_stack_fire=tiff.imread('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_sm_fire.tif')\n",
    "\n",
    "large_image_stack_test=tiff.imread('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/m_3411849_se_11_060_20180722.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a53206a9-d461-49b7-b11f-e9a17f1ff2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated \n",
    "# https://stackoverflow.com/questions/68224588/problem-when-using-patchify-library-to-create-patches\n",
    "\n",
    "import cv2\n",
    "\n",
    "# read large_image_stack_test\n",
    "img = cv2.imread('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/m_3411849_se_11_060_20180722.tif')\n",
    "# type(img)\n",
    "# arr_shape=np.array(img.shape)\n",
    "# print(arr_shape)\n",
    "# window_shape=np.array((128,128,3))\n",
    "# print(window_shape)\n",
    "patches_img = patchify(img, (128,128,3), step=128)\n",
    "\n",
    "for i in range(patches_img.shape[0]):\n",
    "    for j in range(patches_img.shape[1]):\n",
    "        single_patch_img = patches_img[i, j, 0, :, :, :]\n",
    "        if not cv2.imwrite('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/fire_patches' + 'image_' + '_'+ str(i)+str(j)+'.jpg', single_patch_img):\n",
    "            raise Exception(\"Could not write the image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6259f1a1-71f1-4ea7-906f-3d5497a683a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`window_shape` is too large",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(large_image_stack_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m      3\u001b[0m     large_image\u001b[38;5;241m=\u001b[39mlarge_image_stack_test[img]\n\u001b[0;32m----> 5\u001b[0m     patches_img\u001b[38;5;241m=\u001b[39m\u001b[43mpatchify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlarge_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# step=256 for 256 patches means no overlap\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(patches_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(patches_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/gis/lib/python3.10/site-packages/patchify/__init__.py:32\u001b[0m, in \u001b[0;36mpatchify\u001b[0;34m(image, patch_size, step)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpatchify\u001b[39m(image: np\u001b[38;5;241m.\u001b[39mndarray, patch_size: Imsize, step: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Split a 2D or 3D image into small patches given the patch size.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    >>> assert (reconstructed_image == image).all()\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mview_as_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/gis/lib/python3.10/site-packages/patchify/view_as_windows.py:41\u001b[0m, in \u001b[0;36mview_as_windows\u001b[0;34m(arr_in, window_shape, step)\u001b[0m\n\u001b[1;32m     38\u001b[0m window_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(window_shape, dtype\u001b[38;5;241m=\u001b[39marr_shape\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((arr_shape \u001b[38;5;241m-\u001b[39m window_shape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`window_shape` is too large\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((window_shape \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`window_shape` is too small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: `window_shape` is too large"
     ]
    }
   ],
   "source": [
    "for img in range(large_image_stack_test.shape[0]):\n",
    "    \n",
    "    large_image=large_image_stack_test[img]\n",
    "    \n",
    "    patches_img=patchify(large_image,(128,128),step=128) # step=256 for 256 patches means no overlap\n",
    "    \n",
    "    for i in range(patches_img.shape[0]):\n",
    "        for j in range(patches_img.shape[1]):\n",
    "            \n",
    "            single_patch_img=patches_img[i,j,:,:]\n",
    "            tiff.imwrite('patches/images/'+'image_'+'str(img)'+'_'+str(i)+str(j)+\".tif\",single_patch_img)\n",
    "            \n",
    "            \n",
    "# for msk in range(large_image_stack_test.shape[0]):\n",
    "    \n",
    "#     large_mask=large_mask_stack[msk]\n",
    "    \n",
    "#     patches_mask = patchify(large_mask,(64,64),step=64) # same guidance as above\n",
    "    \n",
    "#     for i in range(patches_mask.shape[0]):\n",
    "#         for j in range(patches_mask.shape[1]):\n",
    "\n",
    "#             single_patch_mask=patches_mask[i,j,:,:]\n",
    "#             tiff.imwrite('patches/masks'+'mask'+str(msk)+'_'+str(i)+str(j)+\".tif\",single_patch_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c621fe-a168-4f51-97da-4209924c8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in range(large_image_stack_fire.shape[0]):\n",
    "    \n",
    "    large_image=large_image_stack_fire[img]\n",
    "    \n",
    "    patches_img=patchify(large_image,(256,256),step=256) # step=256 for 256 patches means no overlap\n",
    "    \n",
    "    for i in range(patches_img.shape[0]):\n",
    "        for j in range(patches_img.shape[1]):\n",
    "            \n",
    "            single_patch_img=patches_img[i,j,:,:]\n",
    "            tiff.imwrite('patches/images/'+'image_'+'str(img)'+'_'+str(i)+str(j)+\".tif\",single_patch_img)\n",
    "            \n",
    "            \n",
    "for msk in range(large_image_stack_fire.shape[0]):\n",
    "    \n",
    "    large_mask=large_mask_stack[msk]\n",
    "    \n",
    "    patches_mask = patchify(large_mask,(256,256),step=256) # same guidance as above\n",
    "    \n",
    "    for i in range(patches_mask.shape[0]):\n",
    "        for j in range(patches_mask.shape[1]):\n",
    "\n",
    "            single_patch_mask=patches_mask[i,j,:,:]\n",
    "            tiff.imwrite('patches/masks'+'mask'+str(msk)+'_'+str(i)+str(j)+\".tif\",single_patch_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0232ee1-e748-4191-9fd4-2a52e12ba5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "# from patchify import patchify\n",
    "# import tifffile as tiff\n",
    "\n",
    "# large_image_stack_nofire=tiff.imread('/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_sm_nofire.tif')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36f6d2b-f209-448e-b47e-64098b133f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ChatGPT\n",
    "# how do you split into patches a geotiff image?\n",
    "\n",
    "# To split a GeoTIFF image into patches, you can use a combination of GIS software and programming tools. Here's a general workflow you could follow:\n",
    "\n",
    "# Open the GeoTIFF image in a GIS software, such as QGIS or ArcGIS.\n",
    "# Determine the size of the patches you want to create. This will depend on the resolution of the image and the purpose of the patches. For example, you may want to create patches that are 256x256 pixels for use in deep learning models.\n",
    "# Use the GIS software to create a grid of polygons that covers the extent of the image. The size of the polygons should match the patch size you determined in step 2.\n",
    "# Export the grid of polygons as a shapefile or other vector format.\n",
    "# Use a programming language, such as Python, to loop through each polygon in the shapefile and extract the corresponding patch from the GeoTIFF image using a raster processing library, such as GDAL or Rasterio.\n",
    "# Save each patch as a separate image file, such as a JPEG or PNG.\n",
    "# Here's some sample Python code that uses the Rasterio library to extract patches from a GeoTIFF image based on a shapefile grid:\n",
    "# (code below)\n",
    "# Note that this is just one possible approach, and the specific details of the workflow will depend on your particular use case and the GIS and programming tools you have available.\n",
    "\n",
    "# this block is testing on a smaller image\n",
    "# m_3411849_se_11_060_20180722.tif\n",
    "\n",
    "# import rasterio\n",
    "# import geopandas as gpd\n",
    "# import os\n",
    "\n",
    "# # Set file paths\n",
    "# tif_file = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/m_3411849_se_11_060_20180722.tif\"\n",
    "# shp_file = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/grid/grid_spacing_100m.geojson\"\n",
    "# out_folder = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018_retile_fire\"\n",
    "\n",
    "# # Open the GeoTIFF image\n",
    "# with rasterio.open(tif_file) as src:\n",
    "\n",
    "#     # Open the shapefile grid\n",
    "#     grid = gpd.read_file(shp_file)\n",
    "\n",
    "#     # Loop through each polygon in the grid\n",
    "#     for idx, row in grid.iterrows():\n",
    "\n",
    "#         # Extract the polygon geometry as a GeoJSON-like object\n",
    "#         geom = row.geometry.__geo_interface__\n",
    "\n",
    "#         # Use Rasterio to read the patch as a numpy array\n",
    "#         patch = src.read(window=rasterio.features.geometry_mask([geom], \n",
    "#                    out_shape=src.shape, transform=src.transform, invert=True))\n",
    "\n",
    "#         # Set the output file path\n",
    "#         out_path = os.path.join(out_folder, f\"patch_{idx}.png\")\n",
    "\n",
    "#         # Save the patch as a PNG image\n",
    "#         rasterio.plot.show(patch, cmap='gray', title=f\"Patch {idx}\")\n",
    "#         plt.savefig(out_path, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ce5d0-b8c5-4c22-af0a-d422f05f02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fullsize\n",
    "# # remember to do the nofire image too\n",
    "\n",
    "# import rasterio\n",
    "# import geopandas as gpd\n",
    "# import os\n",
    "\n",
    "# # Fire\n",
    "# # Set file paths\n",
    "# tif_file = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018/ortho_2018_sm_fire.tif\"\n",
    "# shp_file = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/shapefiles/grid/grid_spacing_100m.geojson\"\n",
    "# out_folder = \"/Users/sra/Desktop/Data_Science_2023/_capstone/00_capstone_data/orthoimagery/2018_retile_fire\"\n",
    "\n",
    "# # Open the GeoTIFF image\n",
    "# with rasterio.open(tif_file) as src:\n",
    "\n",
    "#     # Open the shapefile grid\n",
    "#     grid = gpd.read_file(shp_file)\n",
    "\n",
    "#     # Loop through each polygon in the grid\n",
    "#     for idx, row in grid.iterrows():\n",
    "\n",
    "#         # Extract the polygon geometry as a GeoJSON-like object\n",
    "#         geom = row.geometry.__geo_interface__\n",
    "\n",
    "#         # Use Rasterio to read the patch as a numpy array\n",
    "#         patch = src.read(window=rasterio.features.geometry_mask([geom], \n",
    "#                    out_shape=src.shape, transform=src.transform, invert=True))\n",
    "\n",
    "#         # Set the output file path\n",
    "#         out_path = os.path.join(out_folder, f\"patch_{idx}.png\")\n",
    "\n",
    "#         # Save the patch as a PNG image\n",
    "#         rasterio.plot.show(patch, cmap='gray', title=f\"Patch {idx}\")\n",
    "#         plt.savefig(out_path, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac2b384-ff39-40ef-bd5c-a5b59a82e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gis.stackexchange.com/questions/221671/splitting-tif-image-into-several-tiles\n",
    "\n",
    "# import os, gdal\n",
    "\n",
    "# in_path = 'C:/Users/Marco/Desktop/'\n",
    "# input_filename = 'dtm_5.tif'\n",
    "\n",
    "# out_path = 'C:/Users/Marco/Desktop/output_folder/'\n",
    "# output_filename = 'tile_'\n",
    "\n",
    "# tile_size_x = 50\n",
    "# tile_size_y = 70\n",
    "\n",
    "# ds = gdal.Open(in_path + input_filename)\n",
    "# band = ds.GetRasterBand(1)\n",
    "# xsize = band.XSize\n",
    "# ysize = band.YSize\n",
    "\n",
    "# for i in range(0, xsize, tile_size_x):\n",
    "#     for j in range(0, ysize, tile_size_y):\n",
    "#         com_string = \"gdal_translate -of GTIFF -srcwin \" + str(i)+ \", \" + str(j) + \", \" + str(tile_size_x) + \", \" + str(tile_size_y) + \" \" + str(in_path) + str(input_filename) + \" \" + str(out_path) + str(output_filename) + str(i) + \"_\" + str(j) + \".tif\"\n",
    "#         os.system(com_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "gis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
